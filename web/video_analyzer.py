# -*- coding: utf-8 -*-
"""
è§†é¢‘åˆ†ææ¨¡å— - Video Analyzer Module
=====================================

é«˜å¾·çº³çš„æ–‡å­¦ç¼–ç¨‹: ä»£ç åº”è¯¥åƒæ–‡ç« ä¸€æ ·å¯è¯»ã€‚
ç»´ç‰¹æ ¹æ–¯å¦çš„è¯­è¨€æ¸…æ™°: è¯´æ¸…æ¥šèƒ½è¯´çš„ï¼Œå¯¹ä¸èƒ½è¯´çš„ä¿æŒæ²‰é»˜ã€‚

æ¨¡å—åŠŸèƒ½:
---------
1. è§†é¢‘æŠ½å¸§ (VideoFrameExtractor)
   - æŒ‰å›ºå®šæ—¶é—´é—´éš”æå–
   - åŸºäºåœºæ™¯å˜åŒ–æ£€æµ‹æå–
   - æ··åˆæ¨¡å¼

2. OCRè¯†åˆ« (OllamaVisionClient)
   - è°ƒç”¨æœ¬åœ° Ollama qwen3-vl:4b æ¨¡å‹
   - æ”¯æŒé‡è¯•å’Œè¶…æ—¶å¤„ç†

3. æ™ºèƒ½åˆ†æ (ClaudeAnalyzer)
   - è°ƒç”¨ Claude Code CLI
   - æ•…äº‹ç»“æ„ã€è§’è‰²ã€åœºæ™¯ã€åˆ†é•œåˆ†æ

4. æ—¶é—´é”šç‚¹ç³»ç»Ÿ
   - å…³é”®å¸§ä¸åˆ†æå†…å®¹åŒå‘å…³è”
   - æ”¯æŒæ—¶é—´è½´å¯¼èˆª

5. æŠ¥å‘Šç”Ÿæˆ (PDFReportGenerator)
   - PDFæŠ¥å‘Šè¾“å‡º
   - HTMLå¤‡é€‰æ–¹æ¡ˆ

è®¾è®¡å“²å­¦ (ç”±20ä½å¤§å¸ˆå®¡æ ¸):
------------------------
- è‹æ ¼æ‹‰åº•: è¯˜é—®å¼é”™è¯¯å¤„ç†
- äºšé‡Œå£«å¤šå¾·: å®Œå¤‡çš„ç±»å‹åˆ†ç±»
- ç¬›å¡å°”: æ–¹æ³•è®ºæ€€ç–‘çš„è¾“å…¥éªŒè¯
- åº·å¾·: å…ˆéªŒé…ç½®ä¸æ¥å£å¥‘çº¦
- æ¬§æ‹‰/é«˜æ–¯: æ•°å­¦ç®€æ´ä¸ç²¾ç¡®
- å›¾çµ: å¯åœæœºçš„åˆ†ææµç¨‹
- è¿ªæ°æ–¯ç‰¹æ‹‰: ç»“æ„åŒ–ç¼–ç¨‹
- é«˜å¾·çº³: æ–‡å­¦ç¼–ç¨‹ä¸ç®—æ³•ä¼˜åŒ–

Version: 2.0.0
Author: AI åˆ†é•œ Pro Team
"""

import os
import json
import subprocess
import tempfile
import base64
import requests
from abc import ABC, abstractmethod
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Any, Optional, Tuple, Protocol
from datetime import datetime
from enum import Enum
import uuid
import cv2
import numpy as np
from pathlib import Path


# ========================================
# åº·å¾·: å…ˆéªŒé…ç½® - æ™®éæ³•åˆ™å®šä¹‰
# ========================================

@dataclass
class AnalyzerConfig:
    """
    åº·å¾·çš„ç»å¯¹å‘½ä»¤: é…ç½®åº”è¯¥æ˜¯å…ˆéªŒçš„ã€æ™®éçš„ã€å¯éªŒè¯çš„

    æ‰€æœ‰å¯é…ç½®é¡¹é›†ä¸­ç®¡ç†ï¼Œé¿å…é­”æ³•æ•°å­—ã€‚
    """
    # Ollama é…ç½®
    ollama_host: str = "localhost"
    ollama_port: int = 11434
    ollama_model: str = "qwen3-vl:4b"
    ollama_timeout: int = 60
    ollama_max_retries: int = 3

    # æŠ½å¸§é…ç½®
    default_interval_seconds: float = 5.0
    default_max_frames: int = 50
    scene_change_threshold: float = 30.0
    min_scene_interval: float = 2.0

    # è¾“å‡ºé…ç½®
    output_dir: str = ""
    frame_quality: int = 90  # JPEGè´¨é‡
    max_video_size_gb: float = 10.0

    # åˆ†æé…ç½®
    max_frames_for_analysis: int = 50
    max_frames_for_tags: int = 20
    claude_timeout: int = 180

    def __post_init__(self):
        if not self.output_dir:
            self.output_dir = os.path.join(os.getcwd(), "video_analysis")


# åº·å¾·: æ¥å£å¥‘çº¦ - æ™®éæ³•åˆ™
class ImageAnalyzerProtocol(Protocol):
    """åº·å¾·çš„ç»å¯¹å‘½ä»¤: å›¾åƒåˆ†æå™¨å¿…é¡»éµå®ˆçš„å¥‘çº¦"""

    def test_connection(self) -> Tuple[bool, str]:
        """æµ‹è¯•è¿æ¥"""
        ...

    def analyze_image(self, image_path: str, prompt: str) -> Tuple[str, float]:
        """åˆ†æå›¾åƒ"""
        ...


class TextAnalyzerProtocol(Protocol):
    """åº·å¾·çš„ç»å¯¹å‘½ä»¤: æ–‡æœ¬åˆ†æå™¨å¿…é¡»éµå®ˆçš„å¥‘çº¦"""

    def analyze_video_content(self, frames_data: List[Dict], video_info: Dict) -> Dict[str, Any]:
        """åˆ†æè§†é¢‘å†…å®¹"""
        ...


# ========================================
# æ¬§æ‹‰ & é«˜æ–¯: æ•°å­¦å·¥å…·å‡½æ•° - ç®€æ´ä¸”ç²¾ç¡®
# ========================================

def format_timestamp(seconds: float) -> str:
    """
    æ¬§æ‹‰çš„ç®€æ´: å°†ç§’æ•°æ ¼å¼åŒ–ä¸º HH:MM:SS.mmm

    é«˜æ–¯çš„ç²¾ç¡®: æ¯«ç§’ç²¾åº¦ï¼Œæ— æµ®ç‚¹è¯¯å·®
    """
    total_ms = int(seconds * 1000)
    ms = total_ms % 1000
    total_seconds = total_ms // 1000
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:02d}.{ms:03d}"


def format_duration(seconds: float) -> str:
    """æ¬§æ‹‰çš„ç®€æ´: æ ¼å¼åŒ–æ—¶é•¿ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    if hours > 0:
        return f"{hours}h {minutes}m {secs}s"
    elif minutes > 0:
        return f"{minutes}m {secs}s"
    else:
        return f"{secs}s"


def bytes_to_human(size_bytes: int) -> str:
    """æ¬§æ‹‰çš„ç®€æ´: å­—èŠ‚è½¬äººç±»å¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f}{unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f}PB"


class AnalysisStatus(Enum):
    """åˆ†æçŠ¶æ€ - äºšé‡Œå£«å¤šå¾·: ç©·å°½æ‰€æœ‰å¯èƒ½çŠ¶æ€"""
    PENDING = "pending"          # ç­‰å¾…ä¸­
    EXTRACTING = "extracting"    # æŠ½å¸§ä¸­
    OCR_PROCESSING = "ocr_processing"  # OCRå¤„ç†ä¸­
    ANALYZING = "analyzing"      # åˆ†æä¸­
    COMPLETED = "completed"      # å®Œæˆ
    FAILED = "failed"            # å¤±è´¥
    CANCELLED = "cancelled"      # å·²å–æ¶ˆ
    PAUSED = "paused"            # å·²æš‚åœ


class FrameType(Enum):
    """å¸§ç±»å‹ - äºšé‡Œå£«å¤šå¾·: äº’æ–¥ä¸”ç©·å°½çš„åˆ†ç±»"""
    KEYFRAME = "keyframe"        # å…³é”®å¸§ (Iå¸§)
    INTERVAL = "interval"        # é—´éš”å¸§
    SCENE_CHANGE = "scene_change"  # åœºæ™¯åˆ‡æ¢å¸§
    DIALOG = "dialog"            # å¯¹è¯å¸§
    ACTION = "action"            # åŠ¨ä½œå¸§
    TRANSITION = "transition"    # è½¬åœºå¸§
    TITLE = "title"              # æ ‡é¢˜/å­—å¹•å¸§


class ShotType(Enum):
    """é•œå¤´ç±»å‹ - äºšé‡Œå£«å¤šå¾·: ç”µå½±è¯­è¨€çš„é€»è¾‘åˆ†ç±»"""
    EXTREME_LONG = "extreme_long"    # å¤§è¿œæ™¯
    LONG = "long"                    # è¿œæ™¯
    FULL = "full"                    # å…¨æ™¯
    MEDIUM_LONG = "medium_long"      # ä¸­è¿œæ™¯
    MEDIUM = "medium"                # ä¸­æ™¯
    MEDIUM_CLOSE = "medium_close"    # ä¸­è¿‘æ™¯
    CLOSE = "close"                  # è¿‘æ™¯
    EXTREME_CLOSE = "extreme_close"  # ç‰¹å†™
    INSERT = "insert"                # æ’å…¥é•œå¤´


class CameraAngle(Enum):
    """æ‘„åƒæœºè§’åº¦ - äºšé‡Œå£«å¤šå¾·: è§†è§’çš„é€»è¾‘åˆ†ç±»"""
    EYE_LEVEL = "eye_level"      # å¹³è§†
    HIGH_ANGLE = "high_angle"    # ä¿¯è§†
    LOW_ANGLE = "low_angle"      # ä»°è§†
    DUTCH_ANGLE = "dutch_angle"  # æ–œè§’
    BIRDS_EYE = "birds_eye"      # é¸Ÿç°
    WORMS_EYE = "worms_eye"      # è™«è§†


class CameraMovement(Enum):
    """æ‘„åƒæœºè¿åŠ¨ - äºšé‡Œå£«å¤šå¾·: è¿åŠ¨çš„é€»è¾‘åˆ†ç±»"""
    STATIC = "static"        # å›ºå®š
    PAN = "pan"              # æ‘‡ (æ°´å¹³)
    TILT = "tilt"            # ä¿¯ä»° (å‚ç›´)
    ZOOM = "zoom"            # æ¨æ‹‰
    DOLLY = "dolly"          # ç§»åŠ¨
    TRACK = "track"          # è·Ÿè¸ª
    CRANE = "crane"          # å‡é™
    HANDHELD = "handheld"    # æ‰‹æŒ


@dataclass
class ExtractedFrame:
    """æå–çš„å¸§æ•°æ®"""
    id: str = ""
    timestamp: float = 0.0  # ç§’
    frame_number: int = 0
    frame_type: FrameType = FrameType.INTERVAL
    image_path: str = ""
    ocr_text: str = ""
    ocr_confidence: float = 0.0
    tags: List[str] = field(default_factory=list)
    scene_description: str = ""

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]

    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "timestamp": self.timestamp,
            "timestamp_formatted": self.format_timestamp(),
            "frame_number": self.frame_number,
            "frame_type": self.frame_type.value,
            "image_path": self.image_path,
            "ocr_text": self.ocr_text,
            "ocr_confidence": self.ocr_confidence,
            "tags": self.tags,
            "scene_description": self.scene_description
        }

    def format_timestamp(self) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸º HH:MM:SS.ms"""
        hours = int(self.timestamp // 3600)
        minutes = int((self.timestamp % 3600) // 60)
        seconds = int(self.timestamp % 60)
        ms = int((self.timestamp % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{ms:03d}"


@dataclass
class StoryPoint:
    """æ•…äº‹èŠ‚ç‚¹/çˆ½ç‚¹"""
    id: str = ""
    timestamp: float = 0.0
    title: str = ""
    description: str = ""
    point_type: str = ""  # å¼€åœºã€é“ºå«ã€é«˜æ½®ã€è½¬æŠ˜ã€ç»“å±€
    emotional_impact: str = ""
    related_frames: List[str] = field(default_factory=list)

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class CharacterAnalysis:
    """è§’è‰²åˆ†æ"""
    id: str = ""
    name: str = ""
    first_appearance: float = 0.0
    role_type: str = ""  # ä¸»è§’ã€é…è§’ã€åæ´¾
    appearance_description: str = ""
    personality_traits: List[str] = field(default_factory=list)
    key_moments: List[float] = field(default_factory=list)
    related_frames: List[str] = field(default_factory=list)

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class SceneAnalysis:
    """åœºæ™¯åˆ†æ"""
    id: str = ""
    start_time: float = 0.0
    end_time: float = 0.0
    scene_name: str = ""
    location_type: str = ""
    atmosphere: str = ""
    lighting: str = ""
    key_elements: List[str] = field(default_factory=list)
    related_frames: List[str] = field(default_factory=list)

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class ShotAnalysis:
    """åˆ†é•œåˆ†æ"""
    id: str = ""
    timestamp: float = 0.0
    shot_type: str = ""  # è¿œæ™¯ã€ä¸­æ™¯ã€è¿‘æ™¯ã€ç‰¹å†™
    camera_angle: str = ""  # å¹³è§†ã€ä¿¯è§†ã€ä»°è§†
    camera_movement: str = ""  # å›ºå®šã€æ¨ã€æ‹‰ã€æ‘‡ã€ç§»
    composition: str = ""
    purpose: str = ""
    related_frame: str = ""

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class VideoAnalysisResult:
    """å®Œæ•´çš„è§†é¢‘åˆ†æç»“æœ"""
    id: str = ""
    video_path: str = ""
    video_name: str = ""
    duration: float = 0.0
    fps: float = 0.0
    resolution: Tuple[int, int] = (0, 0)

    # åˆ†æç»“æœ
    story_summary: str = ""
    story_structure: str = ""
    storyboard: str = ""  # ä¸“ä¸šåˆ†é•œè„šæœ¬ (ä¸­æ–‡)
    story_points: List[StoryPoint] = field(default_factory=list)
    characters: List[CharacterAnalysis] = field(default_factory=list)
    scenes: List[SceneAnalysis] = field(default_factory=list)
    shots: List[ShotAnalysis] = field(default_factory=list)
    frames: List[ExtractedFrame] = field(default_factory=list)

    # å…ƒæ•°æ®
    status: AnalysisStatus = AnalysisStatus.PENDING
    created_at: str = ""
    completed_at: str = ""
    error_message: str = ""

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())[:8]
        if not self.created_at:
            self.created_at = datetime.now().isoformat()

    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "video_path": self.video_path,
            "video_name": self.video_name,
            "duration": self.duration,
            "duration_formatted": self._format_duration(),
            "fps": self.fps,
            "resolution": list(self.resolution),
            "story_summary": self.story_summary,
            "story_structure": self.story_structure,
            "storyboard": self.storyboard,
            "story_points": [sp.to_dict() for sp in self.story_points],
            "characters": [c.to_dict() for c in self.characters],
            "scenes": [s.to_dict() for s in self.scenes],
            "shots": [sh.to_dict() for sh in self.shots],
            "frames": [f.to_dict() for f in self.frames],
            "status": self.status.value,
            "created_at": self.created_at,
            "completed_at": self.completed_at,
            "error_message": self.error_message
        }

    def _format_duration(self) -> str:
        hours = int(self.duration // 3600)
        minutes = int((self.duration % 3600) // 60)
        seconds = int(self.duration % 60)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"


class OllamaVisionClient:
    """Ollama Vision å®¢æˆ·ç«¯ - è°ƒç”¨æœ¬åœ° qwen3-vl:4b"""

    def __init__(self, host: str = "localhost", port: int = 11434, model: str = "qwen3-vl:4b"):
        self.base_url = f"http://{host}:{port}"
        self.model = model

    def test_connection(self) -> Tuple[bool, str]:
        """æµ‹è¯•è¿æ¥"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m.get("name", "") for m in models]
                if any(self.model in name for name in model_names):
                    return True, f"å·²è¿æ¥ Ollamaï¼Œæ¨¡å‹ {self.model} å¯ç”¨"
                else:
                    return False, f"Ollama å·²è¿æ¥ï¼Œä½†æœªæ‰¾åˆ°æ¨¡å‹ {self.model}ã€‚å¯ç”¨æ¨¡å‹: {model_names}"
            return False, f"è¿æ¥å¤±è´¥: HTTP {response.status_code}"
        except requests.exceptions.ConnectionError:
            return False, f"æ— æ³•è¿æ¥åˆ° Ollama ({self.base_url})"
        except Exception as e:
            return False, f"è¿æ¥é”™è¯¯: {str(e)}"

    def analyze_image(self, image_path: str, prompt: str = None, max_retries: int = 3) -> Tuple[str, float]:
        """
        åˆ†æå›¾åƒï¼Œè¿”å› OCR æ–‡æœ¬å’Œç½®ä¿¡åº¦

        è‹æ ¼æ‹‰åº•è¯˜é—®: å¦‚æœå¤±è´¥æ€ä¹ˆåŠï¼Ÿæ·»åŠ é‡è¯•æœºåˆ¶ã€‚

        Args:
            image_path: å›¾åƒè·¯å¾„
            prompt: è‡ªå®šä¹‰æç¤ºè¯­
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            (ocr_text, confidence)
        """
        if prompt is None:
            prompt = """è¯·ä»”ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **æ–‡å­—è¯†åˆ«(OCR)**ï¼šè¯†åˆ«å›¾ç‰‡ä¸­æ‰€æœ‰å¯è§çš„æ–‡å­—ï¼ŒåŒ…æ‹¬å¯¹è¯æ¡†ã€å­—å¹•ã€æ ‡é¢˜ã€æ—ç™½ç­‰
2. **åœºæ™¯æè¿°**ï¼šç®€è¦æè¿°ç”»é¢å†…å®¹

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{
    "ocr_text": "è¯†åˆ«åˆ°çš„æ‰€æœ‰æ–‡å­—",
    "scene_description": "åœºæ™¯æè¿°",
    "has_dialog": true/false,
    "dialog_content": "å¦‚æœ‰å¯¹è¯ï¼Œåˆ—å‡ºå¯¹è¯å†…å®¹"
}"""

        import time

        for attempt in range(max_retries):
            try:
                # è¯»å–å›¾åƒå¹¶è½¬ä¸º base64
                with open(image_path, "rb") as f:
                    image_data = base64.b64encode(f.read()).decode("utf-8")

                # è°ƒç”¨ Ollama API
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "images": [image_data],
                        "stream": False,
                        "options": {
                            "temperature": 0.1,
                            "num_predict": 1024
                        }
                    },
                    timeout=60
                )

                if response.status_code == 200:
                    result = response.json()
                    text = result.get("response", "")
                    # å°è¯•è§£æ JSON
                    try:
                        # æå– JSON éƒ¨åˆ†
                        import re
                        json_match = re.search(r'\{[\s\S]*\}', text)
                        if json_match:
                            parsed = json.loads(json_match.group())
                            ocr_text = parsed.get("ocr_text", "")
                            return ocr_text, 0.85
                    except:
                        pass
                    return text, 0.7
                elif attempt < max_retries - 1:
                    time.sleep(1 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    return "", 0.0

            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"Ollama åˆ†æé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    time.sleep(1 * (attempt + 1))
                    continue
                print(f"Ollama åˆ†ææœ€ç»ˆå¤±è´¥: {e}")
                return "", 0.0

        return "", 0.0

    def batch_analyze(self, image_paths: List[str], progress_callback=None) -> List[Tuple[str, float]]:
        """æ‰¹é‡åˆ†æå›¾åƒ"""
        results = []
        total = len(image_paths)

        for i, path in enumerate(image_paths):
            text, confidence = self.analyze_image(path)
            results.append((text, confidence))

            if progress_callback:
                progress_callback(i + 1, total, path)

        return results


class ClaudeAnalyzer:
    """Claude CLI åˆ†æå™¨"""

    def __init__(self):
        self.claude_cmd = "claude"

    def _call_claude(self, prompt: str, timeout: int = 120) -> str:
        """è°ƒç”¨ Claude CLI"""
        try:
            result = subprocess.run(
                [self.claude_cmd, "-p", prompt, "--output-format", "text"],
                capture_output=True,
                text=True,
                timeout=timeout,
                encoding="utf-8"
            )

            if result.returncode == 0:
                return result.stdout.strip()
            else:
                print(f"Claude CLI é”™è¯¯: {result.stderr}")
                return ""

        except subprocess.TimeoutExpired:
            print("Claude CLI è¶…æ—¶")
            return ""
        except Exception as e:
            print(f"Claude CLI è°ƒç”¨é”™è¯¯: {e}")
            return ""

    def analyze_video_content(self, frames_data: List[Dict], video_info: Dict) -> Dict[str, Any]:
        """
        ç»¼åˆåˆ†æè§†é¢‘å†…å®¹ - ä¸“ä¸šçº§æ·±åº¦æ‹†è§£

        Args:
            frames_data: å¸§æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«æ—¶é—´æˆ³ã€OCRæ–‡æœ¬ã€åœºæ™¯æè¿°
            video_info: è§†é¢‘åŸºæœ¬ä¿¡æ¯

        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        # æ„å»ºåˆ†ææç¤ºè¯­ - åŒ…å«å‰åå¸§ä¿¡æ¯ç”¨äºè¿é•œåˆ†æ
        frames_text = ""
        for i, f in enumerate(frames_data[:80]):
            prev_info = f"(å‰ä¸€å¸§: {frames_data[i-1].get('scene_description', '')[:30]})" if i > 0 else ""
            next_info = f"(åä¸€å¸§: {frames_data[i+1].get('scene_description', '')[:30]})" if i < len(frames_data)-1 else ""
            frames_text += f"ã€{f['timestamp_formatted']}ã€‘{f.get('ocr_text', '')} | åœºæ™¯: {f.get('scene_description', '')} {prev_info} {next_info}\n"

        prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å½±è§†åˆ†æå¸ˆã€åˆ†é•œå¸ˆå’Œç¼–å‰§ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘æŠ½å¸§ä¿¡æ¯ï¼Œè¿›è¡Œã€æå…¶è¯¦ç»†ã€‘çš„ä¸“ä¸šçº§å‰§æœ¬æ‹†è§£åˆ†æã€‚

## è§†é¢‘åŸºæœ¬ä¿¡æ¯
- è§†é¢‘æ—¶é•¿: {video_info.get('duration_formatted', 'N/A')}
- å¸§ç‡: {video_info.get('fps', 'N/A')} fps
- åˆ†è¾¨ç‡: {video_info.get('resolution', 'N/A')}

## æŠ½å¸§ä¿¡æ¯ï¼ˆæ—¶é—´æˆ³ | OCRæ–‡å­— | åœºæ™¯æè¿° | å‰åå¸§å‚è€ƒï¼‰
{frames_text}

## åˆ†æè¦æ±‚
ä½ éœ€è¦è¿›è¡Œã€å€’æ¨å‰§æœ¬æ‹†è§£ã€‘ï¼Œåƒä¸“ä¸šå¯¼æ¼”å’Œåˆ†é•œå¸ˆä¸€æ ·è¯¦ç»†åˆ†ææ¯ä¸€ä¸ªé•œå¤´ã€‚
é‡ç‚¹å…³æ³¨ï¼š
1. å‰§æƒ…æ‹†è§£ - æ•…äº‹è„‰ç»œã€æƒ…èŠ‚ç‚¹ã€å™äº‹èŠ‚å¥
2. äººç‰©æ‹†è§£ - è§’è‰²å½¢è±¡ã€è¡¨æƒ…ã€æœé¥°ã€å‘å‹ã€çŠ¶æ€
3. é•œå¤´æ‹†è§£ï¼ˆæ ¸å¿ƒé‡ç‚¹ï¼‰- æ™¯åˆ«ã€æœºä½ã€è¿é•œæ–¹å‘ã€æ„å›¾æ„å›¾
4. å‰åå¸§è¿é•œæ–¹å‘ - é•œå¤´å¦‚ä½•ä»ä¸Šä¸€å¸§è¿‡æ¸¡åˆ°å½“å‰å¸§

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ã€éå¸¸è¯¦ç»†ã€‘çš„åˆ†æç»“æœï¼š

{{
    "story_summary": "æ•…äº‹æ¦‚è¦ï¼ˆ300å­—ä»¥ä¸Šï¼Œè¯¦ç»†æè¿°æ•…äº‹ä¸»çº¿ã€å†²çªã€äººç‰©å…³ç³»ï¼‰",
    "story_structure": "æ•…äº‹ç»“æ„åˆ†æï¼ˆè¯¦ç»†åˆ†æèµ·æ‰¿è½¬åˆã€ä¸‰å¹•ç»“æ„ã€èŠ‚å¥æ›²çº¿ï¼Œè‡³å°‘200å­—ï¼‰",

    "story_points": [
        {{
            "timestamp": 0.0,
            "title": "èŠ‚ç‚¹æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°ï¼ˆè‡³å°‘100å­—ï¼ŒåŒ…å«è¿™ä¸ªèŠ‚ç‚¹çš„å‰§æƒ…å†…å®¹ã€æƒ…æ„Ÿå˜åŒ–ã€äººç‰©çŠ¶æ€ï¼‰",
            "point_type": "å¼€åœº/é“ºå«/å‘å±•/é«˜æ½®/è½¬æŠ˜/ç»“å±€",
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»æè¿°ï¼ˆè§‚ä¼—çš„æƒ…ç»ªååº”ï¼‰",
            "narrative_function": "å™äº‹åŠŸèƒ½ï¼ˆè¿™ä¸ªèŠ‚ç‚¹åœ¨æ•´ä½“æ•…äº‹ä¸­çš„ä½œç”¨ï¼‰"
        }}
    ],

    "characters": [
        {{
            "name": "è§’è‰²å",
            "first_appearance": 0.0,
            "role_type": "ä¸»è§’/é…è§’/åæ´¾/è·¯äºº",
            "appearance_description": "å¤–è²Œè¯¦ç»†æè¿°ï¼ˆè‡³å°‘150å­—ï¼‰ï¼šé¢éƒ¨ç‰¹å¾ã€å¹´é¾„ç‰¹å¾ã€èº«ææ¯”ä¾‹ã€çš®è‚¤è´¨æ„Ÿ",
            "hair_style": "å‘å‹è¯¦ç»†æè¿°ï¼šé•¿åº¦ã€é¢œè‰²ã€é€ å‹ã€è´¨æ„Ÿ",
            "clothing": "æœé¥°è¯¦ç»†æè¿°ï¼šæ¬¾å¼ã€é¢œè‰²ã€æè´¨ã€é…é¥°",
            "expression_range": "è¡¨æƒ…å˜åŒ–èŒƒå›´ï¼šä¸»è¦å‡ºç°çš„è¡¨æƒ…ç±»å‹",
            "body_language": "è‚¢ä½“è¯­è¨€ç‰¹å¾ï¼šå§¿æ€ã€åŠ¨ä½œä¹ æƒ¯",
            "personality_traits": ["ç‰¹å¾1", "ç‰¹å¾2", "ç‰¹å¾3"],
            "character_arc": "è§’è‰²å¼§å…‰ï¼ˆåœ¨è¿™æ®µè§†é¢‘ä¸­çš„å˜åŒ–ï¼‰"
        }}
    ],

    "scenes": [
        {{
            "start_time": 0.0,
            "end_time": 10.0,
            "scene_name": "åœºæ™¯åç§°",
            "location_type": "å®¤å†…/å®¤å¤–/è™šæ‹Ÿç©ºé—´",
            "location_detail": "å…·ä½“ä½ç½®è¯¦ç»†æè¿°ï¼ˆè‡³å°‘100å­—ï¼‰ï¼šç©ºé—´å¸ƒå±€ã€å®¶å…·æ‘†è®¾ã€è£…é¥°é£æ ¼",
            "atmosphere": "æ°›å›´è¯¦ç»†æè¿°ï¼šæƒ…æ„ŸåŸºè°ƒã€ç´§å¼ ç¨‹åº¦ã€æ¸©åº¦æ„Ÿ",
            "lighting": "å…‰çº¿è¯¦ç»†æè¿°ï¼šå…‰æºæ–¹å‘ã€è‰²æ¸©ã€æ˜æš—å¯¹æ¯”ã€é˜´å½±æ•ˆæœ",
            "color_palette": "è‰²å½©åŸºè°ƒï¼šä¸»è‰²è°ƒã€è¾…åŠ©è‰²ã€ç‚¹ç¼€è‰²",
            "key_elements": ["é‡è¦å…ƒç´ 1", "é‡è¦å…ƒç´ 2"],
            "props": ["é“å…·1ï¼šæè¿°", "é“å…·2ï¼šæè¿°"],
            "sound_atmosphere": "å£°éŸ³æ°›å›´æ¨æµ‹ï¼šç¯å¢ƒéŸ³ã€é…ä¹æƒ…ç»ª"
        }}
    ],

    "shots": [
        {{
            "timestamp": 0.0,
            "end_timestamp": 2.0,
            "shot_number": 1,
            "shot_type": "è¿œæ™¯/å…¨æ™¯/ä¸­æ™¯/è¿‘æ™¯/ç‰¹å†™/å¤§ç‰¹å†™",
            "shot_type_detail": "æ™¯åˆ«è¯¦ç»†è¯´æ˜ï¼ˆå¦‚ï¼šä¸­è¿‘æ™¯åäººç‰©ä¸ŠåŠèº«ï¼‰",
            "camera_angle": "å¹³è§†/ä¿¯è§†/ä»°è§†/æ–œè§’/ä½è§’åº¦/é«˜è§’åº¦",
            "camera_angle_degree": "æœºä½è§’åº¦å…·ä½“æè¿°ï¼ˆå¦‚ï¼šç•¥å¾®ä¿¯è§†çº¦15åº¦ï¼‰",
            "camera_movement": "å›ºå®š/æ¨/æ‹‰/æ‘‡/ç§»/è·Ÿ/å‡/é™/ç¯ç»•",
            "camera_movement_detail": "è¿é•œè¯¦ç»†æè¿°ï¼ˆå¦‚ï¼šç¼“æ…¢æ¨è¿›ï¼Œä»ä¸­æ™¯æ¨åˆ°è¿‘æ™¯ï¼‰",
            "movement_direction": "è¿é•œæ–¹å‘ï¼ˆä»å‰ä¸€å¸§åˆ°å½“å‰å¸§çš„é•œå¤´å˜åŒ–ï¼šå¦‚ä»å·¦åˆ°å³æ‘‡ã€ä»è¿œåˆ°è¿‘æ¨ï¼‰",

            "cut_logic": {{
                "transition_type": "ç¡¬åˆ‡/å åŒ–/æ·¡å…¥/æ·¡å‡º/é—ªç™½/é—ªé»‘/åˆ’åƒ/åŒ¹é…å‰ªè¾‘/è·³åˆ‡/Lå‰ªè¾‘/Jå‰ªè¾‘",
                "cut_reason": "åˆ‡é•œåŸå› ï¼ˆä¸ºä»€ä¹ˆåœ¨è¿™é‡Œåˆ‡ï¼šæƒ…ç»ªè½¬æ¢/è§†è§’åˆ‡æ¢/æ—¶é—´è·³è·ƒ/ç©ºé—´è½¬ç§»/å¼ºè°ƒé‡ç‚¹/èŠ‚å¥éœ€è¦ï¼‰",
                "cut_timing": "åˆ‡ç‚¹é€‰æ‹©ç†ç”±ï¼ˆä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ—¶é—´ç‚¹åˆ‡ï¼šåŠ¨ä½œå®Œæˆç‚¹/å°è¯ç»“æŸ/è¡¨æƒ…å˜åŒ–/è§†çº¿å¼•å¯¼ï¼‰",
                "continuity_type": "è¿ç»­æ€§ç±»å‹ï¼ˆåŠ¨ä½œè¿ç»­/è§†çº¿è¿ç»­/å£°éŸ³è¿ç»­/æƒ…ç»ªè¿ç»­/å›¾å½¢è¿ç»­ï¼‰",
                "axis_compliance": "è½´çº¿è§„åˆ™ï¼ˆæ˜¯å¦éµå®ˆ180åº¦è½´çº¿/æœ‰æ— è¶Šè½´/è¶Šè½´åŸå› ï¼‰",
                "rhythm_function": "èŠ‚å¥åŠŸèƒ½ï¼ˆåŠ é€Ÿ/å‡é€Ÿ/åœé¡¿/å¼ºè°ƒ/å‘¼å¸ç‚¹ï¼‰",
                "emotional_beat": "æƒ…æ„ŸèŠ‚æ‹ï¼ˆè¿™ä¸ªåˆ‡ç‚¹å¯¹åº”çš„æƒ…æ„Ÿå˜åŒ–ï¼‰",
                "prev_shot_relation": "ä¸å‰é•œå¤´å…³ç³»ï¼ˆæ­£åæ‰“/ä¸»è§‚-å®¢è§‚/å…¨-åˆ†/å› -æœ/å¹³è¡Œï¼‰",
                "next_shot_setup": "ä¸ºä¸‹ä¸€é•œå¤´çš„é“ºå«ï¼ˆè§†çº¿å¼•å¯¼/åŠ¨ä½œå»¶ç»­/æ‚¬å¿µè®¾ç½®ï¼‰"
            }},

            "editing_technique": {{
                "montage_type": "è’™å¤ªå¥‡ç±»å‹ï¼ˆå™äº‹è’™å¤ªå¥‡/è¡¨ç°è’™å¤ªå¥‡/ç†æ€§è’™å¤ªå¥‡/æ— ï¼‰",
                "screen_direction": "ç”»é¢æ–¹å‘ï¼ˆäººç‰©/ç‰©ä½“è¿åŠ¨æ–¹å‘ï¼šå·¦â†’å³/å³â†’å·¦/å‘é•œå¤´/èƒŒé•œå¤´ï¼‰",
                "eye_trace": "è§†çº¿å¼•å¯¼ï¼ˆè§‚ä¼—è§†çº¿ä»ç”»é¢å“ªé‡Œç§»åŠ¨åˆ°å“ªé‡Œï¼‰",
                "match_elements": "åŒ¹é…å…ƒç´ ï¼ˆä¸å‰åé•œå¤´åŒ¹é…çš„è§†è§‰å…ƒç´ ï¼šé¢œè‰²/å½¢çŠ¶/åŠ¨ä½œ/ä½ç½®ï¼‰",
                "contrast_elements": "å¯¹æ¯”å…ƒç´ ï¼ˆä¸å‰åé•œå¤´å½¢æˆå¯¹æ¯”çš„å…ƒç´ ï¼‰"
            }},

            "composition": "æ„å›¾è¯¦ç»†åˆ†æï¼ˆè‡³å°‘80å­—ï¼‰ï¼šä¸»ä½“ä½ç½®ã€é»„é‡‘åˆ†å‰²ã€å¼•å¯¼çº¿ã€å‰æ™¯ä¸­æ™¯åæ™¯å±‚æ¬¡",
            "depth_of_field": "æ™¯æ·±æ•ˆæœï¼šç„¦ç‚¹ä½ç½®ã€è™šåŒ–ç¨‹åº¦",
            "character_position": "äººç‰©åœ¨ç”»é¢ä¸­çš„ä½ç½®ï¼šå·¦/ä¸­/å³ã€ä¸Š/ä¸­/ä¸‹ï¼Œå ç”»é¢æ¯”ä¾‹",
            "character_state": "äººç‰©å½“å‰çŠ¶æ€ï¼šè¡¨æƒ…ã€å§¿æ€ã€åŠ¨ä½œã€è§†çº¿æ–¹å‘",
            "purpose": "é•œå¤´ç›®çš„ï¼ˆå™äº‹åŠŸèƒ½ã€æƒ…æ„Ÿä¼ è¾¾ã€è§†è§‰é‡ç‚¹ï¼‰",
            "visual_style": "è§†è§‰é£æ ¼ï¼šæ»¤é•œã€è‰²è°ƒã€è´¨æ„Ÿ"
        }}
    ],

    "highlights": [
        {{
            "timestamp": 0.0,
            "type": "çˆ½ç‚¹ç±»å‹ï¼ˆåè½¬/æ‰“è„¸/é«˜èƒ½/è™å¿ƒ/ç”œèœœ/ç‡ƒï¼‰",
            "description": "çˆ½ç‚¹è¯¦ç»†æè¿°ï¼ˆè‡³å°‘100å­—ï¼‰",
            "technique": "è¡¨ç°æ‰‹æ³•ï¼ˆé•œå¤´ã€å‰ªè¾‘ã€éŸ³ä¹å¦‚ä½•é…åˆï¼‰",
            "audience_reaction": "é¢„æœŸè§‚ä¼—ååº”"
        }}
    ],

    "professional_notes": {{
        "pacing": "èŠ‚å¥è¯¦ç»†åˆ†æï¼ˆè‡³å°‘150å­—ï¼‰ï¼šæ•´ä½“èŠ‚å¥æ›²çº¿ã€å¿«æ…¢åˆ‡æ¢ã€æƒ…ç»ªèµ·ä¼",
        "visual_style": "è§†è§‰é£æ ¼åˆ†æï¼ˆè‡³å°‘100å­—ï¼‰ï¼šæ•´ä½“ç¾å­¦ã€è‰²å½©è¿ç”¨ã€å…‰å½±ç‰¹ç‚¹",
        "narrative_technique": "å™äº‹æŠ€å·§åˆ†æï¼šå™äº‹è§†è§’ã€æ—¶é—´çº¿å¤„ç†ã€æ‚¬å¿µè®¾ç½®",
        "cinematography": "æ‘„å½±æŠ€æ³•æ€»ç»“ï¼šä¸»è¦è¿é•œæ‰‹æ³•ã€é•œå¤´è¯­è¨€ç‰¹ç‚¹",
        "editing_style": "å‰ªè¾‘é£æ ¼ï¼šå‰ªè¾‘èŠ‚å¥ã€è½¬åœºæ–¹å¼ã€è’™å¤ªå¥‡è¿ç”¨",
        "target_audience": "ç›®æ ‡å—ä¼—åˆ†æ",
        "genre_elements": "ç±»å‹å…ƒç´ ï¼šå±äºä»€ä¹ˆç±»å‹ï¼Œæœ‰å“ªäº›ç±»å‹ç‰¹å¾",
        "strengths": ["ä¼˜ç‚¹1ï¼ˆå…·ä½“è¯´æ˜ï¼‰", "ä¼˜ç‚¹2"],
        "suggestions": ["ä¸“ä¸šå»ºè®®1", "ä¸“ä¸šå»ºè®®2"]
    }}
}}

è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚æ¯ä¸ªå­—æ®µéƒ½è¦å°½é‡è¯¦ç»†ï¼Œç‰¹åˆ«æ˜¯shotséƒ¨åˆ†è¦ä½“ç°ä¸“ä¸šçš„é•œå¤´åˆ†æèƒ½åŠ›ã€‚"""

        result = self._call_claude(prompt, timeout=300)  # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥æ”¯æŒè¯¦ç»†åˆ†æ

        if result:
            try:
                # æå– JSON
                import re
                json_match = re.search(r'\{[\s\S]*\}', result)
                if json_match:
                    return json.loads(json_match.group())
            except json.JSONDecodeError as e:
                print(f"JSON è§£æé”™è¯¯: {e}")

        return {}

    def generate_storyboard(self, frames_data: List[Dict], video_info: Dict) -> str:
        """
        ç”Ÿæˆä¸“ä¸šçº§æ·±åº¦åˆ†é•œè„šæœ¬ (ä¸­æ–‡è¾“å‡ºï¼Œæ¯é•œå¤´500å­—ä»¥ä¸Š)

        è¿›è¡Œå€’æ¨å‰§æœ¬æ‹†è§£ï¼Œè¯¦ç»†æè¿°ï¼š
        - åœºæ™¯ç¯å¢ƒã€æ°›å›´ã€å…‰çº¿
        - äººç‰©å¤–è²Œã€è¡¨æƒ…ã€æœé¥°ã€å‘å‹
        - ç‰©å“é“å…·ã€çŠ¶æ€
        - äººç‰©äº¤äº’ã€åŠ¨ä½œ
        - ç”»é¢é£æ ¼ã€è‰²è°ƒ
        - é•œå¤´ç±»å‹ã€è¿é•œæ–¹å‘
        - ä¸å‰åå¸§çš„å…³ç³»

        Args:
            frames_data: å¸§æ•°æ®åˆ—è¡¨
            video_info: è§†é¢‘ä¿¡æ¯

        Returns:
            æ ¼å¼åŒ–çš„è¯¦ç»†åˆ†é•œè„šæœ¬æ–‡æœ¬
        """
        # æŒ‰æ—¶é—´é¡ºåºæ•´ç†å¸§ä¿¡æ¯ï¼ŒåŒ…å«å‰åå¸§å‚è€ƒ
        frames_text = ""
        for i, f in enumerate(frames_data[:60]):
            prev_scene = frames_data[i-1].get('scene_description', '')[:50] if i > 0 else "æ— "
            next_scene = frames_data[i+1].get('scene_description', '')[:50] if i < len(frames_data)-1 else "æ— "
            frames_text += f"""
[{f.get('timestamp', 0):.1f}ç§’]
  OCR: {f.get('ocr_text', 'æ— ')}
  åœºæ™¯: {f.get('scene_description', '')}
  å‰å¸§å‚è€ƒ: {prev_scene}
  åå¸§å‚è€ƒ: {next_scene}
"""

        prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶çº§çš„åˆ†é•œå¸ˆã€ç¼–å‰§å’Œå½±è§†åˆ†æä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘æŠ½å¸§ä¿¡æ¯ï¼Œç”Ÿæˆã€æå…¶è¯¦ç»†ã€‘çš„ä¸“ä¸šåˆ†é•œè„šæœ¬ã€‚

## è§†é¢‘ä¿¡æ¯
- æ—¶é•¿: {video_info.get('duration_formatted', 'N/A')}
- å¸§ç‡: {video_info.get('fps', 'N/A')} fps
- åˆ†è¾¨ç‡: {video_info.get('resolution', 'N/A')}

## æŠ½å¸§æ•°æ®ï¼ˆåŒ…å«å‰åå¸§å‚è€ƒç”¨äºåˆ†æè¿é•œæ–¹å‘ï¼‰
{frames_text}

## æ ¸å¿ƒè¦æ±‚ - å€’æ¨å‰§æœ¬æ‹†è§£
è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€å€’æ¨å‰§æœ¬æ‹†è§£ã€‘ä»»åŠ¡ï¼Œç›®çš„æ˜¯ä»æˆç‰‡åæ¨å‡ºå®Œæ•´çš„åˆ†é•œè„šæœ¬ã€‚
æ¯ä¸ªé•œå¤´çš„æè¿°å¿…é¡»ã€ä¸å°‘äº500å­—ã€‘ï¼Œè¯¦ç»†åˆ°å¯ä»¥è®©ç”»å¸ˆç›´æ¥ç»˜åˆ¶åˆ†é•œç¨¿ã€‚

## æ¯ä¸ªé•œå¤´å¿…é¡»åŒ…å«ä»¥ä¸‹å…¨éƒ¨å†…å®¹ï¼š

### 1. åŸºç¡€ä¿¡æ¯
- æ—¶é—´èŒƒå›´ï¼ˆå¦‚ï¼š0.1ï½2ç§’ï¼‰
- æ™¯åˆ«ï¼šè¿œæ™¯/å…¨æ™¯/ä¸­æ™¯/ä¸­è¿‘æ™¯/è¿‘æ™¯/ç‰¹å†™/å¤§ç‰¹å†™
- æœºä½è§’åº¦ï¼šå¹³è§†/ä¿¯è§†/ä»°è§†/æ–œè§’/ä½è§’åº¦/é«˜è§’åº¦ï¼ˆå«å…·ä½“è§’åº¦ï¼‰
- è¿é•œæ–¹å¼ï¼šå›ºå®š/æ¨/æ‹‰/æ‘‡/ç§»/è·Ÿ/å‡/é™/ç¯ç»•/æ‰‹æŒ
- è¿é•œæ–¹å‘ï¼šä»å‰ä¸€å¸§åˆ°å½“å‰å¸§çš„é•œå¤´è¿åŠ¨æ–¹å‘ï¼ˆå¦‚ï¼šä»å·¦æ‘‡åˆ°å³ã€ä»è¿œæ¨åˆ°è¿‘ï¼‰

### 2. åœºæ™¯æè¿°ï¼ˆè‡³å°‘100å­—ï¼‰
- åœºæ™¯ç±»å‹ï¼šå®¤å†…/å®¤å¤–/è™šæ‹Ÿç©ºé—´
- å…·ä½“ç¯å¢ƒï¼šç©ºé—´å¸ƒå±€ã€å»ºç­‘ç»“æ„
- é™ˆè®¾é“å…·ï¼šå®¶å…·ã€è£…é¥°ç‰©ã€é‡è¦ç‰©å“
- å…‰çº¿æ¡ä»¶ï¼šå…‰æºæ–¹å‘ã€è‰²æ¸©ã€æ˜æš—å¯¹æ¯”
- æ°›å›´åŸºè°ƒï¼šå†·æš–ã€ç´§å¼ /è½»æ¾ã€å‹æŠ‘/æ˜æœ—

### 3. äººç‰©æè¿°ï¼ˆæ¯ä¸ªäººç‰©è‡³å°‘100å­—ï¼‰
- äººç‰©ä½ç½®ï¼šåœ¨ç”»é¢ä¸­çš„ä½ç½®ï¼ˆå·¦/ä¸­/å³ã€å‰æ™¯/ä¸­æ™¯/åæ™¯ï¼‰
- å ç”»é¢æ¯”ä¾‹ï¼šäººç‰©åœ¨ç”»é¢ä¸­å æ®çš„å¤§å°
- é¢éƒ¨è¡¨æƒ…ï¼šå…·ä½“è¡¨æƒ…æè¿°ï¼ˆçœ¼ç¥ã€å˜´è§’ã€çœ‰æ¯›ï¼‰
- å‘å‹æè¿°ï¼šé•¿åº¦ã€é¢œè‰²ã€é€ å‹ã€æ˜¯å¦æœ‰å‘é¥°
- æœé¥°æè¿°ï¼šæ¬¾å¼ã€é¢œè‰²ã€æè´¨ã€é…é¥°
- è‚¢ä½“çŠ¶æ€ï¼šå§¿æ€ã€æ‰‹åŠ¿ã€åŠ¨ä½œ
- è§†çº¿æ–¹å‘ï¼šçœ‹å‘å“ªé‡Œ
- æƒ…ç»ªçŠ¶æ€ï¼šå†…å¿ƒæƒ…æ„Ÿ

### 4. ç‰©å“/é“å…·ï¼ˆå¦‚æœ‰ï¼‰
- ç‰©å“åç§°å’Œæè¿°
- åœ¨ç”»é¢ä¸­çš„ä½ç½®
- ä¸äººç‰©çš„å…³ç³»

### 5. äººç‰©äº¤äº’ï¼ˆå¦‚æœ‰å¤šäººï¼‰
- äººç‰©ä¹‹é—´çš„ç©ºé—´å…³ç³»
- äº’åŠ¨åŠ¨ä½œ
- çœ¼ç¥äº¤æµ
- æƒ…æ„ŸæµåŠ¨

### 6. ç”»é¢é£æ ¼
- æ•´ä½“è‰²è°ƒï¼šæš–è‰²/å†·è‰²/ä¸­æ€§
- æ»¤é•œæ•ˆæœï¼šæ¸…æ–°/å¤å¤/ç”µå½±æ„Ÿ
- ç”»é¢è´¨æ„Ÿï¼šå†™å®/æ¢¦å¹»/ç¡¬æœ—

### 7. é•œå¤´ç›®çš„
- å™äº‹åŠŸèƒ½ï¼šè¿™ä¸ªé•œå¤´åœ¨æ•…äº‹ä¸­çš„ä½œç”¨
- æƒ…æ„Ÿä¼ è¾¾ï¼šä¼ é€’ä»€ä¹ˆæƒ…ç»ª
- è§†è§‰é‡ç‚¹ï¼šè§‚ä¼—åº”è¯¥æ³¨æ„ä»€ä¹ˆ

### 8. åˆ‡é•œé€»è¾‘ï¼ˆæ ¸å¿ƒé‡ç‚¹ï¼‰
- è½¬åœºæ–¹å¼ï¼šç¡¬åˆ‡/å åŒ–/æ·¡å…¥æ·¡å‡º/é—ªç™½/é—ªé»‘/åˆ’åƒ/åŒ¹é…å‰ªè¾‘/è·³åˆ‡/Lå‰ªè¾‘/Jå‰ªè¾‘
- åˆ‡é•œåŸå› ï¼šä¸ºä»€ä¹ˆåœ¨è¿™é‡Œåˆ‡ï¼ˆæƒ…ç»ªè½¬æ¢/è§†è§’åˆ‡æ¢/æ—¶é—´è·³è·ƒ/ç©ºé—´è½¬ç§»/å¼ºè°ƒé‡ç‚¹/èŠ‚å¥éœ€è¦ï¼‰
- åˆ‡ç‚¹é€‰æ‹©ï¼šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ—¶é—´ç‚¹åˆ‡ï¼ˆåŠ¨ä½œå®Œæˆç‚¹/å°è¯ç»“æŸ/è¡¨æƒ…å˜åŒ–/è§†çº¿å¼•å¯¼ï¼‰
- è¿ç»­æ€§ç±»å‹ï¼šåŠ¨ä½œè¿ç»­/è§†çº¿è¿ç»­/å£°éŸ³è¿ç»­/æƒ…ç»ªè¿ç»­/å›¾å½¢è¿ç»­
- è½´çº¿è§„åˆ™ï¼šæ˜¯å¦éµå®ˆ180åº¦è½´çº¿ï¼Œæœ‰æ— è¶Šè½´åŠåŸå› 
- èŠ‚å¥åŠŸèƒ½ï¼šè¿™ä¸ªåˆ‡ç‚¹åœ¨èŠ‚å¥ä¸Šçš„ä½œç”¨ï¼ˆåŠ é€Ÿ/å‡é€Ÿ/åœé¡¿/å¼ºè°ƒ/å‘¼å¸ç‚¹ï¼‰
- ä¸å‰é•œå¤´å…³ç³»ï¼šæ­£åæ‰“/ä¸»è§‚-å®¢è§‚åˆ‡æ¢/å…¨æ™¯-åˆ†åˆ‡/å› æœå…³ç³»/å¹³è¡Œå‰ªè¾‘
- ä¸åé•œå¤´é“ºå«ï¼šè§†çº¿å¼•å¯¼/åŠ¨ä½œå»¶ç»­/æ‚¬å¿µè®¾ç½®/æƒ…ç»ªæ‰¿æ¥
- ç”»é¢æ–¹å‘ï¼šäººç‰©/ç‰©ä½“è¿åŠ¨æ–¹å‘ï¼ˆå·¦â†’å³/å³â†’å·¦/å‘é•œå¤´/èƒŒé•œå¤´ï¼‰
- è§†çº¿å¼•å¯¼ï¼šè§‚ä¼—è§†çº¿ä»ç”»é¢å“ªé‡Œç§»åŠ¨åˆ°å“ªé‡Œ
- åŒ¹é…å…ƒç´ ï¼šä¸å‰åé•œå¤´åŒ¹é…çš„è§†è§‰å…ƒç´ ï¼ˆé¢œè‰²/å½¢çŠ¶/åŠ¨ä½œ/ä½ç½®ï¼‰

## è¾“å‡ºæ ¼å¼ç¤ºä¾‹

---
ã€é•œå¤´01ã€‘0.1ï½2ç§’
æ™¯åˆ«ï¼šä¸­æ™¯ | æœºä½ï¼šå¹³è§† | è¿é•œï¼šå›ºå®š | è¿‡æ¸¡ï¼šç¡¬åˆ‡å¼€åœº

ã€åœºæ™¯ç¯å¢ƒã€‘
ç°ä»£éƒ½å¸‚é«˜æ¡£å…¬å¯“å®¢å…ï¼Œçº¦50å¹³ç±³çš„å¼€é˜”ç©ºé—´ã€‚æ•´ä½“è£…ä¿®é£æ ¼ä¸ºç°ä»£ç®€çº¦ï¼Œä»¥ç°ç™½è‰²è°ƒä¸ºä¸»ã€‚è½åœ°çª—å¤–æ˜¯åŸå¸‚å¤©é™…çº¿ï¼Œé€è¿‡è–„çº±çª—å¸˜å¯ä»¥çœ‹åˆ°è¿œå¤„çš„é«˜æ¥¼å¤§å¦ï¼Œé˜³å…‰ä»çª—æˆ·æ–œå°„è¿›æ¥ï¼Œåœ¨åœ°æ¿ä¸Šå½¢æˆæ¸©æš–çš„å…‰æ–‘ã€‚å®¢å…ä¸­å¤®æ˜¯ä¸€ç»„æ·±ç°è‰²çš„Lå‹å¸ƒè‰ºæ²™å‘ï¼Œæ²™å‘å‰æ˜¯ä¸€å¼ å¤§ç†çŸ³èŒ¶å‡ ï¼Œä¸Šé¢æ”¾ç€ä¸€æ¯å†’ç€çƒ­æ°”çš„å’–å•¡å’Œä¸€æœ¬ç¿»å¼€çš„æ‚å¿—ã€‚å¢™ä¸ŠæŒ‚ç€ä¸€å¹…æŠ½è±¡è‰ºæœ¯ç”»ï¼Œä¸ºç©ºé—´å¢æ·»äº†å‡ åˆ†è‰ºæœ¯æ°”æ¯ã€‚æ•´ä½“å…‰çº¿æŸ”å’Œï¼Œè‰²æ¸©åæš–ï¼Œè¥é€ å‡ºèˆ’é€‚æƒ¬æ„çš„å±…å®¶æ°›å›´ã€‚

ã€äººç‰©æè¿°ã€‘
å¥³ä¸»è§’ä½äºç”»é¢ä¸­å¤®åå³ï¼Œå ç”»é¢çº¦1/3ã€‚å¥¹æ˜¯ä¸€ä½çº¦25å²çš„å¹´è½»å¥³æ€§ï¼Œäº”å®˜ç²¾è‡´ï¼Œçš®è‚¤ç™½çš™ç»†è…»ã€‚æ­¤åˆ»å¥¹çš„è¡¨æƒ…å¹³é™ä¸­å¸¦ç€ä¸€ä¸è‹¥æœ‰æ‰€æ€ï¼Œçœ‰å¤´å¾®å¾®çš±èµ·ï¼Œå˜´è§’ä¿æŒè‡ªç„¶å¼§åº¦ã€‚å¥¹çš„çœ¼ç¥æœ›å‘çª—å¤–ï¼Œä¼¼ä¹åœ¨æ€è€ƒä»€ä¹ˆã€‚

å‘å‹ï¼šåŠè…°çš„é»‘è‰²é•¿ç›´å‘ï¼Œå‘è´¨æŸ”é¡ºæœ‰å…‰æ³½ï¼Œè‡ªç„¶å‚è½åœ¨è‚©è†€ä¸¤ä¾§ï¼Œæ²¡æœ‰åˆ˜æµ·ï¼Œéœ²å‡ºå…‰æ´çš„é¢å¤´ã€‚å·¦è€³ååˆ«ç€ä¸€æšç²¾è‡´çš„çç å‘å¤¹ã€‚

æœé¥°ï¼šèº«ç©¿ä¸€ä»¶ç±³ç™½è‰²çš„å®½æ¾é’ˆç»‡æ¯›è¡£ï¼Œé¢†å£ä¸ºVé¢†è®¾è®¡ï¼Œéœ²å‡ºé”éª¨çº¿æ¡ã€‚ä¸‹èº«æ­é…æµ…ç°è‰²çš„ä¼‘é—²é•¿è£¤ã€‚æ‰‹è…•ä¸Šæˆ´ç€ä¸€åªç®€çº¦çš„ç«ç‘°é‡‘æ‰‹è¡¨ã€‚æ•´ä½“ç©¿æ­é£æ ¼ç®€çº¦å¤§æ–¹ï¼Œé€å‡ºçŸ¥æ€§ä¼˜é›…çš„æ°”è´¨ã€‚

è‚¢ä½“çŠ¶æ€ï¼šå¥¹ååœ¨æ²™å‘ä¸Šï¼Œèº«ä½“ç•¥å¾®åä»°é ç€é èƒŒï¼ŒåŒè…¿è‡ªç„¶äº¤å ã€‚å³æ‰‹è½»è½»æ‰¶ç€å’–å•¡æ¯ï¼Œå·¦æ‰‹æ­åœ¨æ²™å‘æ‰¶æ‰‹ä¸Šã€‚å§¿æ€æ”¾æ¾ä½†ä¸æ…µæ‡’ï¼Œé€å‡ºä¸€ç§ä»å®¹ä¸è¿«çš„æ°”è´¨ã€‚

ã€ç”»é¢é£æ ¼ã€‘
æ•´ä½“è‰²è°ƒåæš–ï¼Œä»¥ç±³ç™½ã€æµ…ç°ã€åŸæœ¨è‰²ä¸ºä¸»ï¼Œç”»é¢å¹²å‡€é€šé€ã€‚é‡‡ç”¨ç”µå½±æ„Ÿè°ƒè‰²ï¼Œå¯¹æ¯”åº¦é€‚ä¸­ï¼Œé«˜å…‰æŸ”å’Œã€‚ç”»é¢è´¨æ„Ÿç»†è…»ï¼Œæœ‰ä¸€å®šçš„æ™¯æ·±æ•ˆæœï¼ŒèƒŒæ™¯çš„åŸå¸‚å¤©é™…çº¿ç•¥å¾®è™šåŒ–ï¼Œå°†è§‚ä¼—çš„æ³¨æ„åŠ›é›†ä¸­åœ¨å¥³ä¸»è§’èº«ä¸Šã€‚

ã€é•œå¤´ç›®çš„ã€‘
è¿™æ˜¯ä¸€ä¸ªå»ºç«‹æ€§é•œå¤´ï¼Œç”¨äºä»‹ç»å¥³ä¸»è§’çš„ç”Ÿæ´»ç¯å¢ƒå’ŒåŸºæœ¬å½¢è±¡ã€‚é€šè¿‡é«˜æ¡£å…¬å¯“å’Œç²¾è‡´çš„ç©¿æ­ï¼Œæš—ç¤ºå¥³ä¸»è§’çš„ç¤¾ä¼šåœ°ä½å’Œç”Ÿæ´»å“è´¨ã€‚å¥¹è‹¥æœ‰æ‰€æ€çš„è¡¨æƒ…ä¸ºåç»­å‰§æƒ…åŸ‹ä¸‹ä¼ç¬”ï¼Œå¼•å‘è§‚ä¼—å¯¹å¥¹å†…å¿ƒä¸–ç•Œçš„å¥½å¥‡ã€‚

ã€åˆ‡é•œé€»è¾‘ã€‘
è½¬åœºæ–¹å¼ï¼šç¡¬åˆ‡å¼€åœºï¼Œé»‘åœºç›´æ¥åˆ‡å…¥ç”»é¢
åˆ‡é•œåŸå› ï¼šä½œä¸ºå¼€åœºé•œå¤´ï¼Œéœ€è¦å¿«é€Ÿå»ºç«‹åœºæ™¯å’Œäººç‰©
åˆ‡ç‚¹é€‰æ‹©ï¼šé€‰æ‹©å¥³ä¸»è§’é™æ€æ€è€ƒçš„ç¬é—´ï¼Œç»™è§‚ä¼—ç•™å‡ºè§‚å¯Ÿå’Œé€‚åº”çš„æ—¶é—´
è¿ç»­æ€§ï¼šæ— å‰ç½®é•œå¤´ï¼Œä½œä¸ºåºåˆ—èµ·ç‚¹
è½´çº¿è§„åˆ™ï¼šå»ºç«‹åŸºç¡€è½´çº¿ï¼Œå¥³ä¸»è§’é¢å‘ç”»é¢å³ä¾§ï¼Œä¸ºåç»­æ­£åæ‰“é¢„ç•™ç©ºé—´
èŠ‚å¥åŠŸèƒ½ï¼šå¼€åœºå‘¼å¸ç‚¹ï¼ŒèŠ‚å¥è¾ƒæ…¢ï¼Œè®©è§‚ä¼—æ²‰æµ¸
ä¸åé•œå¤´é“ºå«ï¼šå¥³ä¸»è§’çš„è§†çº¿æ–¹å‘ï¼ˆçœ‹å‘çª—å¤–å³ä¾§ï¼‰ä¸ºä¸‹ä¸€é•œå¤´çš„åˆ‡å…¥æ–¹å‘æä¾›å¼•å¯¼
ç”»é¢æ–¹å‘ï¼šé™æ€é•œå¤´ï¼Œå¥³ä¸»è§’é¢å‘å³ä¾§ï¼Œå»ºç«‹ç”»é¢æ–¹å‘åŸºå‡†
è§†çº¿å¼•å¯¼ï¼šè§‚ä¼—è§†çº¿ä»ç”»é¢ä¸­å¤®çš„å¥³ä¸»è§’å¼€å§‹ï¼Œæ²¿å…¶è§†çº¿æ–¹å‘ç§»å‘çª—å¤–
åŒ¹é…å…ƒç´ ï¼šæš–è‰²è°ƒå’Œå®¤å†…ç¯å¢ƒå°†åœ¨åç»­é•œå¤´ä¸­ä¿æŒä¸€è‡´ï¼Œå½¢æˆè§†è§‰è¿è´¯

[cut]
---

è¯·æŒ‰ç…§ä»¥ä¸Šæ ¼å¼ï¼Œä¸ºè§†é¢‘ç”Ÿæˆå®Œæ•´çš„åˆ†é•œè„šæœ¬ã€‚æ¯ä¸ªé•œå¤´æè¿°ä¸å°‘äº500å­—ï¼Œåˆ‡é•œé€»è¾‘éƒ¨åˆ†å¿…é¡»è¯¦ç»†åˆ†æã€‚"""

        result = self._call_claude(prompt, timeout=300)  # å¢åŠ è¶…æ—¶æ—¶é—´

        if result:
            return result.strip()

        return "åˆ†é•œè„šæœ¬ç”Ÿæˆå¤±è´¥"

    def generate_production_manual(self, story_text: str, style: str = "ç”µå½±æ„Ÿ", aspect_ratio: str = "16:9") -> str:
        """
        æ ¹æ®å°è¯´/å‰§æœ¬ç”Ÿæˆå®Œæ•´çš„è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œ

        åŒ…å«ï¼š
        - å‰§æƒ…æ‹†è§£
        - äººç‰©è®¾å®š
        - åœºæ™¯è®¾å®š
        - é“å…·æ¸…å•
        - å®Œæ•´åˆ†é•œè„šæœ¬ï¼ˆæ¯é•œå¤´500å­—+ï¼Œå«åˆ‡é•œé€»è¾‘ï¼‰
        - é•œå¤´è¿åŠ¨è®¾è®¡
        - å‰ªè¾‘èŠ‚å¥å»ºè®®

        Args:
            story_text: å°è¯´/å‰§æœ¬æ–‡æœ¬
            style: è§†è§‰é£æ ¼
            aspect_ratio: ç”»é¢æ¯”ä¾‹

        Returns:
            å®Œæ•´çš„è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œ
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å½±è§†å¯¼æ¼”ã€åˆ†é•œå¸ˆå’Œåˆ¶ç‰‡äººã€‚è¯·æ ¹æ®ä»¥ä¸‹å°è¯´/å‰§æœ¬å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ã€æå…¶è¯¦ç»†ã€‘çš„è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œã€‚

## è¾“å…¥å†…å®¹
{story_text[:8000]}

## åˆ¶ä½œå‚æ•°
- è§†è§‰é£æ ¼: {style}
- ç”»é¢æ¯”ä¾‹: {aspect_ratio}

## ä½ éœ€è¦ç”Ÿæˆçš„å†…å®¹

è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„ã€è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œã€‘ï¼ŒåŒ…å«ä»¥ä¸‹æ‰€æœ‰ç« èŠ‚ï¼š

---

# ğŸ“– è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œ

## ç¬¬ä¸€ç« ï¼šå‰§æƒ…æ€»è§ˆ

### 1.1 æ•…äº‹æ¢—æ¦‚ï¼ˆ300å­—ä»¥ä¸Šï¼‰
è¯¦ç»†æè¿°æ•…äº‹ä¸»çº¿ã€æ ¸å¿ƒå†²çªã€äººç‰©å…³ç³»ã€æƒ…æ„Ÿèµ°å‘

### 1.2 æ•…äº‹ç»“æ„åˆ†æ
- ä¸‰å¹•ç»“æ„åˆ’åˆ†
- èµ·æ‰¿è½¬åˆèŠ‚ç‚¹
- æƒ…æ„Ÿæ›²çº¿å›¾ï¼ˆç”¨æ–‡å­—æè¿°ï¼‰
- èŠ‚å¥è®¾è®¡æ„å›¾

### 1.3 ä¸»é¢˜ä¸è°ƒæ€§
- æ ¸å¿ƒä¸»é¢˜
- æƒ…æ„ŸåŸºè°ƒ
- è§†è§‰è°ƒæ€§

---

## ç¬¬äºŒç« ï¼šè§’è‰²è®¾å®š

ä¸ºæ¯ä¸ªè§’è‰²ç”Ÿæˆè¯¦ç»†è®¾å®šå¡ï¼š

### è§’è‰²åï¼šXXX
**åŸºç¡€ä¿¡æ¯**
- å¹´é¾„/æ€§åˆ«/èº«ä»½
- æ€§æ ¼ç‰¹å¾
- è§’è‰²åŠŸèƒ½ï¼ˆä¸»è§’/é…è§’/åæ´¾ï¼‰

**å¤–è²Œè®¾å®šï¼ˆ150å­—ä»¥ä¸Šï¼‰**
- é¢éƒ¨ç‰¹å¾ï¼šäº”å®˜ã€è‚¤è‰²ã€å¹´é¾„æ„Ÿ
- èº«æä½“å‹ï¼šèº«é«˜ã€ä½“æ€
- å‘å‹è®¾å®šï¼šé•¿åº¦ã€é¢œè‰²ã€é€ å‹ã€è´¨æ„Ÿ
- æ ‡å¿—æ€§ç‰¹å¾

**æœè£…è®¾å®š**
- ä¸»è¦é€ å‹ï¼šæ¬¾å¼ã€é¢œè‰²ã€æè´¨
- é…é¥°é“å…·
- æœè£…å˜åŒ–ï¼ˆå¦‚æœ‰åœºæ™¯éœ€è¦ï¼‰

**è¡¨æ¼”æŒ‡å¯¼**
- å¸¸è§è¡¨æƒ…
- è‚¢ä½“è¯­è¨€ç‰¹ç‚¹
- è¯´è¯æ–¹å¼/è¯­æ°”

---

## ç¬¬ä¸‰ç« ï¼šåœºæ™¯è®¾å®š

ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆè¯¦ç»†è®¾å®šï¼š

### åœºæ™¯åï¼šXXX
**åœºæ™¯æ¦‚è¿°**
- åœºæ™¯ç±»å‹ï¼šå®¤å†…/å®¤å¤–
- å‡ºç°æ—¶é—´æ®µ
- å™äº‹åŠŸèƒ½

**ç¯å¢ƒè®¾è®¡ï¼ˆ150å­—ä»¥ä¸Šï¼‰**
- ç©ºé—´å¸ƒå±€
- å»ºç­‘/è£…ä¿®é£æ ¼
- ä¸»è¦é™ˆè®¾
- é‡è¦é“å…·

**å…‰å½±è®¾è®¡**
- ä¸»å…‰æº
- è‰²æ¸©å€¾å‘
- æ˜æš—å¯¹æ¯”
- æ°›å›´è¥é€ 

**å£°éŸ³è®¾è®¡å»ºè®®**
- ç¯å¢ƒéŸ³
- é…ä¹æƒ…ç»ª

---

## ç¬¬å››ç« ï¼šé“å…·æ¸…å•

åˆ—å‡ºæ‰€æœ‰é‡è¦é“å…·ï¼š

| é“å…·å | æè¿° | å‡ºç°åœºæ™¯ | å™äº‹åŠŸèƒ½ |
|--------|------|----------|----------|
| XXX | è¯¦ç»†æè¿° | åœºæ™¯X | åŠŸèƒ½è¯´æ˜ |

---

## ç¬¬äº”ç« ï¼šåˆ†é•œè„šæœ¬

ã€æ ¸å¿ƒç« èŠ‚ - æ¯ä¸ªé•œå¤´æè¿°ä¸å°‘äº500å­—ã€‘

### é•œå¤´01ï¼š0ï½2ç§’

**åŸºç¡€ä¿¡æ¯**
- æ™¯åˆ«ï¼šè¿œæ™¯/å…¨æ™¯/ä¸­æ™¯/è¿‘æ™¯/ç‰¹å†™/å¤§ç‰¹å†™
- æœºä½ï¼šå¹³è§†/ä¿¯è§†/ä»°è§†ï¼ˆå«å…·ä½“è§’åº¦ï¼‰
- è¿é•œï¼šå›ºå®š/æ¨/æ‹‰/æ‘‡/ç§»/è·Ÿ/å‡/é™

**åœºæ™¯æè¿°ï¼ˆ100å­—ä»¥ä¸Šï¼‰**
è¯¦ç»†æè¿°ç”»é¢ä¸­çš„ç¯å¢ƒã€å…‰çº¿ã€æ°›å›´...

**äººç‰©æè¿°ï¼ˆæ¯äºº100å­—ä»¥ä¸Šï¼‰**
- ä½ç½®ï¼šç”»é¢ä¸­çš„å…·ä½“ä½ç½®
- è¡¨æƒ…ï¼šçœ¼ç¥ã€å˜´è§’ã€çœ‰æ¯›
- å‘å‹ï¼šå½“å‰çŠ¶æ€
- æœè£…ï¼šå½“å‰ç©¿ç€
- å§¿æ€ï¼šç«™/å/åŠ¨ä½œ
- è§†çº¿ï¼šçœ‹å‘å“ªé‡Œ
- æƒ…ç»ªï¼šå†…å¿ƒçŠ¶æ€

**ç”»é¢æ„å›¾**
- ä¸»ä½“ä½ç½®
- å‰æ™¯/ä¸­æ™¯/åæ™¯å±‚æ¬¡
- å¼•å¯¼çº¿
- æ™¯æ·±æ•ˆæœ

**ã€åˆ‡é•œé€»è¾‘ã€‘**
- è½¬åœºæ–¹å¼ï¼šç¡¬åˆ‡/å åŒ–/æ·¡å…¥æ·¡å‡º/é—ªç™½/é—ªé»‘/åˆ’åƒ/åŒ¹é…å‰ªè¾‘/è·³åˆ‡/Lå‰ªè¾‘/Jå‰ªè¾‘
- åˆ‡é•œåŸå› ï¼šä¸ºä»€ä¹ˆåœ¨è¿™é‡Œåˆ‡ï¼ˆæƒ…ç»ªè½¬æ¢/è§†è§’åˆ‡æ¢/æ—¶é—´è·³è·ƒ/ç©ºé—´è½¬ç§»/å¼ºè°ƒé‡ç‚¹/èŠ‚å¥éœ€è¦ï¼‰
- åˆ‡ç‚¹é€‰æ‹©ï¼šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ—¶é—´ç‚¹åˆ‡ï¼ˆåŠ¨ä½œå®Œæˆç‚¹/å°è¯ç»“æŸ/è¡¨æƒ…å˜åŒ–/è§†çº¿å¼•å¯¼ï¼‰
- è¿ç»­æ€§ç±»å‹ï¼šåŠ¨ä½œè¿ç»­/è§†çº¿è¿ç»­/å£°éŸ³è¿ç»­/æƒ…ç»ªè¿ç»­/å›¾å½¢è¿ç»­
- è½´çº¿è§„åˆ™ï¼šæ˜¯å¦éµå®ˆ180åº¦è½´çº¿ï¼Œæœ‰æ— è¶Šè½´åŠåŸå› 
- èŠ‚å¥åŠŸèƒ½ï¼šåŠ é€Ÿ/å‡é€Ÿ/åœé¡¿/å¼ºè°ƒ/å‘¼å¸ç‚¹
- ä¸å‰é•œå¤´å…³ç³»ï¼šæ­£åæ‰“/ä¸»è§‚-å®¢è§‚åˆ‡æ¢/å…¨æ™¯-åˆ†åˆ‡/å› æœå…³ç³»/å¹³è¡Œå‰ªè¾‘
- ä¸åé•œå¤´é“ºå«ï¼šè§†çº¿å¼•å¯¼/åŠ¨ä½œå»¶ç»­/æ‚¬å¿µè®¾ç½®/æƒ…ç»ªæ‰¿æ¥
- ç”»é¢æ–¹å‘ï¼šäººç‰©è¿åŠ¨æ–¹å‘ï¼ˆå·¦â†’å³/å³â†’å·¦/å‘é•œå¤´/èƒŒé•œå¤´ï¼‰
- è§†çº¿å¼•å¯¼ï¼šè§‚ä¼—è§†çº¿ç§»åŠ¨è·¯å¾„
- åŒ¹é…å…ƒç´ ï¼šä¸å‰åé•œå¤´åŒ¹é…çš„è§†è§‰å…ƒç´ 

**é•œå¤´ç›®çš„**
- å™äº‹åŠŸèƒ½
- æƒ…æ„Ÿä¼ è¾¾
- è§†è§‰é‡ç‚¹

[cut]

---

## ç¬¬å…­ç« ï¼šå‰ªè¾‘èŠ‚å¥è®¾è®¡

### 6.1 æ•´ä½“èŠ‚å¥æ›²çº¿
æè¿°å…¨ç‰‡çš„èŠ‚å¥èµ°å‘...

### 6.2 é‡ç‚¹æ®µè½å‰ªè¾‘å»ºè®®
- å¼€åœºæ®µè½ï¼šå»ºè®®èŠ‚å¥...
- é«˜æ½®æ®µè½ï¼šå»ºè®®èŠ‚å¥...
- ç»“å°¾æ®µè½ï¼šå»ºè®®èŠ‚å¥...

### 6.3 è½¬åœºè®¾è®¡æ€»è¡¨
| é•œå¤´ | è½¬åœºæ–¹å¼ | æ—¶é•¿ | åŸå›  |
|------|----------|------|------|

---

## ç¬¬ä¸ƒç« ï¼šåˆ¶ä½œæ£€æŸ¥æ¸…å•

### å‰æœŸå‡†å¤‡
- [ ] è§’è‰²é€ å‹ç¡®è®¤
- [ ] åœºæ™¯æ­å»º/é€‰å€
- [ ] é“å…·å‡†å¤‡
- [ ] åˆ†é•œç¡®è®¤

### æ‹æ‘„è¦ç‚¹
- [ ] è½´çº¿æ ‡è®°
- [ ] å…‰ä½è®¾è®¡
- [ ] åŠ¨ä½œé¢„æ¼”

### åæœŸè¦ç‚¹
- [ ] å‰ªè¾‘èŠ‚å¥
- [ ] è°ƒè‰²é£æ ¼
- [ ] éŸ³æ•ˆé…ä¹

---

è¯·æŒ‰ç…§ä»¥ä¸Šæ ¼å¼ï¼Œç”Ÿæˆå®Œæ•´è¯¦ç»†çš„è§†é¢‘åˆ¶ä½œæ“ä½œæ‰‹å†Œã€‚åˆ†é•œéƒ¨åˆ†æ˜¯æ ¸å¿ƒï¼Œæ¯ä¸ªé•œå¤´å¿…é¡»è¯¦ç»†æè¿°ï¼Œç‰¹åˆ«æ˜¯åˆ‡é•œé€»è¾‘å¿…é¡»å®Œæ•´åˆ†æã€‚"""

        result = self._call_claude(prompt, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶ï¼Œå› ä¸ºå†…å®¹å¾ˆé•¿

        if result:
            return result.strip()

        return "è§†é¢‘åˆ¶ä½œæ‰‹å†Œç”Ÿæˆå¤±è´¥"

    def generate_frame_tags(self, frame_data: Dict) -> List[str]:
        """ä¸ºå•å¸§ç”Ÿæˆæ ‡ç­¾"""
        prompt = f"""è¯·ä¸ºè¿™ä¸€å¸§ç”»é¢ç”Ÿæˆ3-5ä¸ªç®€çŸ­çš„æ ‡ç­¾ã€‚

å¸§ä¿¡æ¯ï¼š
- æ—¶é—´æˆ³: {frame_data.get('timestamp_formatted', '')}
- OCRæ–‡å­—: {frame_data.get('ocr_text', '')}
- åœºæ™¯æè¿°: {frame_data.get('scene_description', '')}

è¯·ç›´æ¥è¿”å›æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå®¤å†…,å¯¹è¯,ç´§å¼ æ°›å›´,ç‰¹å†™é•œå¤´"""

        result = self._call_claude(prompt, timeout=30)
        if result:
            return [tag.strip() for tag in result.split(",")]
        return []


class VideoFrameExtractor:
    """è§†é¢‘å¸§æå–å™¨"""

    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or tempfile.mkdtemp(prefix="video_frames_")
        os.makedirs(self.output_dir, exist_ok=True)
        self._temp_dirs = []  # è·Ÿè¸ªä¸´æ—¶ç›®å½•ä»¥ä¾¿æ¸…ç†

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ - è‹æ ¼æ‹‰åº•è¯˜é—®: èµ„æºç®¡ç†"""
        import shutil
        for temp_dir in self._temp_dirs:
            if os.path.exists(temp_dir):
                try:
                    shutil.rmtree(temp_dir)
                except Exception:
                    pass
        self._temp_dirs.clear()

    def get_video_info(self, video_path: str) -> Dict[str, Any]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            return {"error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}

        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = frame_count / fps if fps > 0 else 0

        cap.release()

        return {
            "fps": fps,
            "frame_count": frame_count,
            "width": width,
            "height": height,
            "resolution": (width, height),
            "duration": duration,
            "duration_formatted": self._format_duration(duration)
        }

    def _format_duration(self, seconds: float) -> str:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    def _check_ffmpeg(self) -> bool:
        """æ£€æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ["ffmpeg", "-version"],
                capture_output=True,
                timeout=5
            )
            return result.returncode == 0
        except:
            return False

    def extract_frames_ffmpeg(
        self,
        video_path: str,
        interval_seconds: float = 5.0,
        max_frames: int = 100,
        progress_callback=None
    ) -> List[ExtractedFrame]:
        """
        ä½¿ç”¨ FFmpeg å¿«é€ŸæŠ½å¸§ (æ¯” OpenCV å¿« 5-10 å€)

        Args:
            video_path: è§†é¢‘è·¯å¾„
            interval_seconds: é—´éš”ç§’æ•°
            max_frames: æœ€å¤§å¸§æ•°
            progress_callback: è¿›åº¦å›è°ƒ

        Returns:
            æå–çš„å¸§åˆ—è¡¨
        """
        if not self._check_ffmpeg():
            print("FFmpeg ä¸å¯ç”¨ï¼Œå›é€€åˆ° OpenCV æ–¹æ³•")
            return self.extract_frames_by_interval(
                video_path, interval_seconds, max_frames, progress_callback
            )

        # æ¸…ç†æ—§çš„ FFmpeg è¾“å‡ºæ–‡ä»¶å’Œå¸§æ–‡ä»¶
        import glob
        old_ffmpeg_files = glob.glob(os.path.join(self.output_dir, "ffmpeg_*.jpg"))
        old_frame_files = glob.glob(os.path.join(self.output_dir, "frame_*.jpg"))
        for old_file in old_ffmpeg_files + old_frame_files:
            try:
                os.remove(old_file)
            except:
                pass

        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = self.get_video_info(video_path)
        if "error" in video_info:
            raise ValueError(video_info["error"])

        duration = video_info["duration"]
        fps = video_info["fps"]

        # è®¡ç®—æ—¶é—´æˆ³
        timestamps = []
        current_time = 0
        while current_time < duration and len(timestamps) < max_frames:
            timestamps.append(current_time)
            current_time += interval_seconds

        if progress_callback:
            progress_callback(0, len(timestamps), "FFmpeg æ‰¹é‡æŠ½å¸§ä¸­...")

        # ä½¿ç”¨ FFmpeg çš„ fps filter ä¸€æ¬¡æ€§æŠ½å–æ‰€æœ‰å¸§
        output_pattern = os.path.join(self.output_dir, "ffmpeg_%04d.jpg")

        # è®¡ç®—ç­‰æ•ˆçš„ fps å€¼
        if interval_seconds > 0:
            target_fps = 1.0 / interval_seconds
        else:
            target_fps = fps

        cmd = [
            "ffmpeg",
            "-i", video_path,
            "-vf", f"fps={target_fps}",
            "-frames:v", str(max_frames),
            "-q:v", "2",  # é«˜è´¨é‡ JPEG
            "-y",  # è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
            output_pattern
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode != 0:
                print(f"FFmpeg é”™è¯¯: {result.stderr.decode()}")
                return self.extract_frames_by_interval(
                    video_path, interval_seconds, max_frames, progress_callback
                )

        except subprocess.TimeoutExpired:
            print("FFmpeg è¶…æ—¶ï¼Œå›é€€åˆ° OpenCV")
            return self.extract_frames_by_interval(
                video_path, interval_seconds, max_frames, progress_callback
            )

        # æ”¶é›†ç”Ÿæˆçš„å¸§
        extracted_frames = []
        for i, timestamp in enumerate(timestamps):
            frame_path = os.path.join(self.output_dir, f"ffmpeg_{i+1:04d}.jpg")
            if os.path.exists(frame_path):
                # é‡å‘½åä¸ºç»Ÿä¸€æ ¼å¼ (ä½¿ç”¨ replace ä»¥æ”¯æŒ Windows è¦†ç›–)
                new_path = os.path.join(self.output_dir, f"frame_{i:04d}_{timestamp:.2f}s.jpg")
                if os.path.exists(new_path):
                    os.remove(new_path)
                os.rename(frame_path, new_path)

                extracted_frame = ExtractedFrame(
                    timestamp=timestamp,
                    frame_number=int(timestamp * fps),
                    frame_type=FrameType.INTERVAL,
                    image_path=new_path
                )
                extracted_frames.append(extracted_frame)

            if progress_callback and i % 10 == 0:
                progress_callback(i + 1, len(timestamps), f"å¤„ç†å¸§ {i+1}/{len(timestamps)}")

        if progress_callback:
            progress_callback(len(timestamps), len(timestamps), "FFmpeg æŠ½å¸§å®Œæˆ")

        return extracted_frames

    def extract_frames_by_interval(
        self,
        video_path: str,
        interval_seconds: float = 5.0,
        max_frames: int = 100,
        progress_callback=None
    ) -> List[ExtractedFrame]:
        """
        æŒ‰æ—¶é—´é—´éš”æå–å¸§

        Args:
            video_path: è§†é¢‘è·¯å¾„
            interval_seconds: é—´éš”ç§’æ•°
            max_frames: æœ€å¤§å¸§æ•°
            progress_callback: è¿›åº¦å›è°ƒ (current, total, message)

        Returns:
            æå–çš„å¸§åˆ—è¡¨
        """
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps

        # è®¡ç®—è¦æå–çš„å¸§
        timestamps = []
        current_time = 0
        while current_time < duration and len(timestamps) < max_frames:
            timestamps.append(current_time)
            current_time += interval_seconds

        extracted_frames = []
        total = len(timestamps)

        for i, timestamp in enumerate(timestamps):
            frame_number = int(timestamp * fps)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            ret, frame = cap.read()

            if ret:
                # ä¿å­˜å¸§
                frame_filename = f"frame_{i:04d}_{timestamp:.2f}s.jpg"
                frame_path = os.path.join(self.output_dir, frame_filename)
                cv2.imwrite(frame_path, frame)

                extracted_frame = ExtractedFrame(
                    timestamp=timestamp,
                    frame_number=frame_number,
                    frame_type=FrameType.INTERVAL,
                    image_path=frame_path
                )
                extracted_frames.append(extracted_frame)

            if progress_callback:
                progress_callback(i + 1, total, f"æå–å¸§ {i + 1}/{total}")

        cap.release()
        return extracted_frames

    def extract_scene_change_frames(
        self,
        video_path: str,
        threshold: float = 30.0,
        min_interval: float = 2.0,
        max_frames: int = 50,
        progress_callback=None
    ) -> List[ExtractedFrame]:
        """
        æå–åœºæ™¯åˆ‡æ¢å¸§

        ä½¿ç”¨ç›´æ–¹å›¾å·®å¼‚æ£€æµ‹åœºæ™¯å˜åŒ–
        """
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        min_frame_interval = int(min_interval * fps)

        extracted_frames = []
        prev_hist = None
        last_extracted_frame = -min_frame_interval

        frame_idx = 0
        while frame_idx < total_frames and len(extracted_frames) < max_frames:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if not ret:
                break

            # è®¡ç®—ç›´æ–¹å›¾
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()

            if prev_hist is not None:
                # è®¡ç®—ç›´æ–¹å›¾å·®å¼‚
                diff = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_BHATTACHARYYA)

                if diff > threshold / 100 and (frame_idx - last_extracted_frame) >= min_frame_interval:
                    timestamp = frame_idx / fps
                    frame_filename = f"scene_{len(extracted_frames):04d}_{timestamp:.2f}s.jpg"
                    frame_path = os.path.join(self.output_dir, frame_filename)
                    cv2.imwrite(frame_path, frame)

                    extracted_frame = ExtractedFrame(
                        timestamp=timestamp,
                        frame_number=frame_idx,
                        frame_type=FrameType.SCENE_CHANGE,
                        image_path=frame_path
                    )
                    extracted_frames.append(extracted_frame)
                    last_extracted_frame = frame_idx

            prev_hist = hist
            frame_idx += int(fps / 4)  # æ¯0.25ç§’æ£€æµ‹ä¸€æ¬¡

            if progress_callback:
                progress = int((frame_idx / total_frames) * 100)
                progress_callback(progress, 100, f"æ£€æµ‹åœºæ™¯å˜åŒ–... {progress}%")

        cap.release()
        return extracted_frames


class VideoAnalyzer:
    """è§†é¢‘åˆ†æå™¨ - ä¸»ç±»"""

    # ç¬›å¡å°”æ–¹æ³•è®º: æ”¯æŒçš„è§†é¢‘æ ¼å¼ (å¯éªŒè¯çš„åŸºæœ¬äº‹å®)
    SUPPORTED_FORMATS = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}

    def __init__(self,
                 output_dir: str = None,
                 ollama_host: str = "localhost",
                 ollama_port: int = 11434,
                 ollama_model: str = "qwen3-vl:4b"):

        # åŸºç¡€è¾“å‡ºç›®å½•
        self.base_output_dir = output_dir or os.path.join(os.getcwd(), "outputs", "video_analysis")
        os.makedirs(self.base_output_dir, exist_ok=True)

        # ä¸ºæœ¬æ¬¡è¿è¡Œåˆ›å»ºç‹¬ç«‹ç›®å½•ï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
        run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = os.path.join(self.base_output_dir, f"run_{run_timestamp}")
        os.makedirs(self.output_dir, exist_ok=True)

        self.frame_extractor = VideoFrameExtractor(
            os.path.join(self.output_dir, "frames")
        )
        self.ollama_client = OllamaVisionClient(ollama_host, ollama_port, ollama_model)
        self.claude_analyzer = ClaudeAnalyzer()

        self._current_result: Optional[VideoAnalysisResult] = None
        self._is_cancelled = False  # æ”¯æŒå–æ¶ˆæ“ä½œ

    def get_cleanup_info(self, days_to_keep: int = 1) -> Dict[str, Any]:
        """
        è·å–å¯æ¸…ç†çš„è¿è¡Œç›®å½•ä¿¡æ¯ï¼ˆä¸æ‰§è¡Œæ¸…ç†ï¼‰

        Args:
            days_to_keep: ä¿ç•™æœ€è¿‘å‡ å¤©çš„æ•°æ®ï¼Œé»˜è®¤1å¤©

        Returns:
            åŒ…å«å¯æ¸…ç†ç›®å½•åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        import shutil
        from datetime import timedelta

        cleanup_info = {
            "directories_to_clean": [],
            "directories_to_keep": [],
            "total_size_to_clean": 0,
            "total_size_to_keep": 0,
            "cutoff_date": (datetime.now() - timedelta(days=days_to_keep)).strftime("%Y-%m-%d %H:%M:%S")
        }

        cutoff_time = datetime.now() - timedelta(days=days_to_keep)

        if not os.path.exists(self.base_output_dir):
            return cleanup_info

        for item in os.listdir(self.base_output_dir):
            item_path = os.path.join(self.base_output_dir, item)
            if os.path.isdir(item_path) and item.startswith("run_"):
                # ä»ç›®å½•åè§£ææ—¶é—´æˆ³
                try:
                    # æ ¼å¼: run_YYYYMMDD_HHMMSS
                    timestamp_str = item[4:]  # ç§»é™¤ "run_" å‰ç¼€
                    dir_time = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")

                    # è®¡ç®—ç›®å½•å¤§å°
                    dir_size = sum(
                        os.path.getsize(os.path.join(dirpath, filename))
                        for dirpath, dirnames, filenames in os.walk(item_path)
                        for filename in filenames
                    )

                    dir_info = {
                        "path": item_path,
                        "name": item,
                        "created": dir_time.strftime("%Y-%m-%d %H:%M:%S"),
                        "size_mb": round(dir_size / 1024 / 1024, 2)
                    }

                    if dir_time < cutoff_time:
                        cleanup_info["directories_to_clean"].append(dir_info)
                        cleanup_info["total_size_to_clean"] += dir_size
                    else:
                        cleanup_info["directories_to_keep"].append(dir_info)
                        cleanup_info["total_size_to_keep"] += dir_size

                except (ValueError, OSError):
                    # æ— æ³•è§£æçš„ç›®å½•ï¼ŒåŠ å…¥æ¸…ç†åˆ—è¡¨
                    cleanup_info["directories_to_clean"].append({
                        "path": item_path,
                        "name": item,
                        "created": "æœªçŸ¥",
                        "size_mb": 0
                    })

        # è½¬æ¢å¤§å°ä¸º MB
        cleanup_info["total_size_to_clean_mb"] = round(cleanup_info["total_size_to_clean"] / 1024 / 1024, 2)
        cleanup_info["total_size_to_keep_mb"] = round(cleanup_info["total_size_to_keep"] / 1024 / 1024, 2)

        return cleanup_info

    def cleanup_old_runs(self, days_to_keep: int = 1, confirm: bool = False) -> Dict[str, Any]:
        """
        æ¸…ç†æ—§çš„è¿è¡Œç›®å½•ï¼ˆéœ€è¦ç¡®è®¤ï¼‰

        Args:
            days_to_keep: ä¿ç•™æœ€è¿‘å‡ å¤©çš„æ•°æ®ï¼Œé»˜è®¤1å¤©
            confirm: æ˜¯å¦ç¡®è®¤æ‰§è¡Œæ¸…ç†ï¼Œå¿…é¡»ä¸º True æ‰ä¼šæ‰§è¡Œ

        Returns:
            æ¸…ç†ç»“æœä¿¡æ¯
        """
        import shutil

        result = {
            "success": False,
            "message": "",
            "cleaned_count": 0,
            "cleaned_size_mb": 0,
            "failed": []
        }

        if not confirm:
            result["message"] = "æ¸…ç†æœªæ‰§è¡Œï¼šéœ€è¦è®¾ç½® confirm=True ç¡®è®¤æ¸…ç†"
            return result

        cleanup_info = self.get_cleanup_info(days_to_keep)

        for dir_info in cleanup_info["directories_to_clean"]:
            try:
                shutil.rmtree(dir_info["path"])
                result["cleaned_count"] += 1
                result["cleaned_size_mb"] += dir_info["size_mb"]
            except Exception as e:
                result["failed"].append({
                    "path": dir_info["path"],
                    "error": str(e)
                })

        result["success"] = True
        result["message"] = f"å·²æ¸…ç† {result['cleaned_count']} ä¸ªç›®å½•ï¼Œé‡Šæ”¾ {result['cleaned_size_mb']:.2f} MB"

        if result["failed"]:
            result["message"] += f"ï¼Œ{len(result['failed'])} ä¸ªæ¸…ç†å¤±è´¥"

        return result

    def validate_video_file(self, video_path: str) -> Tuple[bool, str]:
        """
        ç¬›å¡å°”æ–¹æ³•è®ºæ€€ç–‘: éªŒè¯è§†é¢‘æ–‡ä»¶çš„å­˜åœ¨æ€§å’Œæœ‰æ•ˆæ€§

        è´¨ç–‘æ¯ä¸€ä¸ªå‡è®¾ï¼Œç¡®ä¿æ–‡ä»¶ç¡®å®å¯ç”¨ã€‚
        """
        # 1. æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Ÿ
        if not os.path.exists(video_path):
            return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"

        # 2. æ˜¯å¦æ˜¯æ–‡ä»¶ï¼ˆè€Œéç›®å½•ï¼‰ï¼Ÿ
        if not os.path.isfile(video_path):
            return False, f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {video_path}"

        # 3. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒï¼Ÿ
        ext = os.path.splitext(video_path)[1].lower()
        if ext not in self.SUPPORTED_FORMATS:
            return False, f"ä¸æ”¯æŒçš„æ ¼å¼ {ext}ï¼Œæ”¯æŒ: {self.SUPPORTED_FORMATS}"

        # 4. æ–‡ä»¶æ˜¯å¦å¯è¯»ï¼Ÿ
        if not os.access(video_path, os.R_OK):
            return False, f"æ–‡ä»¶ä¸å¯è¯»: {video_path}"

        # 5. æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†ï¼Ÿ
        file_size = os.path.getsize(video_path)
        if file_size == 0:
            return False, "æ–‡ä»¶ä¸ºç©º"
        if file_size > 10 * 1024 * 1024 * 1024:  # 10GB
            return False, f"æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024 / 1024:.1f}GB)ï¼Œå»ºè®®å°äº10GB"

        # 6. å°è¯•æ‰“å¼€è§†é¢‘éªŒè¯
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False, "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼Œå¯èƒ½å·²æŸå"

        # 7. æ£€æŸ¥è§†é¢‘æ˜¯å¦æœ‰å¸§
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()

        if frame_count <= 0:
            return False, "è§†é¢‘æ²¡æœ‰æœ‰æ•ˆå¸§"

        return True, "è§†é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡"

    def cancel_analysis(self):
        """å–æ¶ˆåˆ†æ - ç¬›å¡å°”: æ§åˆ¶æƒåº”è¯¥åœ¨ä½¿ç”¨è€…æ‰‹ä¸­"""
        self._is_cancelled = True

    def test_connections(self) -> Dict[str, Tuple[bool, str]]:
        """æµ‹è¯•æ‰€æœ‰è¿æ¥"""
        results = {}

        # æµ‹è¯• Ollama
        ollama_ok, ollama_msg = self.ollama_client.test_connection()
        results["ollama"] = (ollama_ok, ollama_msg)

        # æµ‹è¯• Claude CLI
        try:
            test_result = subprocess.run(
                ["claude", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            if test_result.returncode == 0:
                results["claude"] = (True, f"Claude CLI å¯ç”¨: {test_result.stdout.strip()}")
            else:
                results["claude"] = (False, "Claude CLI ä¸å¯ç”¨")
        except Exception as e:
            results["claude"] = (False, f"Claude CLI é”™è¯¯: {e}")

        return results

    def analyze_video(
        self,
        video_path: str,
        extraction_mode: str = "interval",  # "interval" or "scene_change" or "both"
        interval_seconds: float = 5.0,
        max_frames: int = 50,
        progress_callback=None
    ) -> VideoAnalysisResult:
        """
        å®Œæ•´çš„è§†é¢‘åˆ†ææµç¨‹

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            extraction_mode: æŠ½å¸§æ¨¡å¼
            interval_seconds: é—´éš”ç§’æ•°ï¼ˆintervalæ¨¡å¼ï¼‰
            max_frames: æœ€å¤§å¸§æ•°
            progress_callback: è¿›åº¦å›è°ƒ (step, total_steps, message)

        Returns:
            VideoAnalysisResult
        """
        video_name = os.path.basename(video_path)

        # åˆ›å»ºç»“æœå¯¹è±¡
        result = VideoAnalysisResult(
            video_path=video_path,
            video_name=video_name,
            status=AnalysisStatus.EXTRACTING
        )
        self._current_result = result

        total_steps = 6  # å¢åŠ åˆ†é•œè„šæœ¬ç”Ÿæˆæ­¥éª¤

        try:
            # Step 1: è·å–è§†é¢‘ä¿¡æ¯
            if progress_callback:
                progress_callback(1, total_steps, "è·å–è§†é¢‘ä¿¡æ¯...")

            video_info = self.frame_extractor.get_video_info(video_path)
            if "error" in video_info:
                result.status = AnalysisStatus.FAILED
                result.error_message = video_info["error"]
                return result

            result.duration = video_info["duration"]
            result.fps = video_info["fps"]
            result.resolution = video_info["resolution"]

            # Step 2: æå–å¸§
            if progress_callback:
                progress_callback(2, total_steps, "æå–è§†é¢‘å¸§...")

            frames = []
            if extraction_mode in ["interval", "both"]:
                # ä½¿ç”¨ FFmpeg å¿«é€ŸæŠ½å¸§ (æ¯” OpenCV å¿« 5-10 å€)
                interval_frames = self.frame_extractor.extract_frames_ffmpeg(
                    video_path, interval_seconds, max_frames
                )
                frames.extend(interval_frames)

            if extraction_mode in ["scene_change", "both"]:
                scene_frames = self.frame_extractor.extract_scene_change_frames(
                    video_path, max_frames=max_frames
                )
                frames.extend(scene_frames)

            # æŒ‰æ—¶é—´æ’åºå¹¶å»é‡
            frames.sort(key=lambda f: f.timestamp)
            result.frames = frames

            # Step 3: OCR è¯†åˆ«
            # å›¾çµ: æ£€æŸ¥åœæœºæ¡ä»¶
            if self._is_cancelled:
                result.status = AnalysisStatus.CANCELLED
                return result

            result.status = AnalysisStatus.OCR_PROCESSING
            if progress_callback:
                progress_callback(3, total_steps, "OCR è¯†åˆ«ä¸­...")

            # è¿ªæ°æ–¯ç‰¹æ‹‰: ç»“æ„åŒ–å¾ªç¯ï¼Œå•ä¸€èŒè´£
            for i, frame in enumerate(result.frames):
                # å›¾çµ: æ¯æ¬¡è¿­ä»£æ£€æŸ¥åœæœº
                if self._is_cancelled:
                    result.status = AnalysisStatus.CANCELLED
                    return result

                ocr_text, confidence = self.ollama_client.analyze_image(frame.image_path)
                frame.ocr_text = ocr_text
                frame.ocr_confidence = confidence

                if progress_callback and i % 5 == 0:
                    progress_callback(3, total_steps, f"OCR è¯†åˆ« {i+1}/{len(result.frames)}...")

            # Step 4: Claude åˆ†æ
            result.status = AnalysisStatus.ANALYZING
            if progress_callback:
                progress_callback(4, total_steps, "AI åˆ†æå†…å®¹...")

            frames_data = [f.to_dict() for f in result.frames]
            analysis = self.claude_analyzer.analyze_video_content(frames_data, video_info)

            if analysis:
                # å¡«å……åˆ†æç»“æœ
                result.story_summary = analysis.get("story_summary", "")
                result.story_structure = analysis.get("story_structure", "")

                # æ•…äº‹èŠ‚ç‚¹
                for sp_data in analysis.get("story_points", []):
                    result.story_points.append(StoryPoint(
                        timestamp=sp_data.get("timestamp", 0),
                        title=sp_data.get("title", ""),
                        description=sp_data.get("description", ""),
                        point_type=sp_data.get("point_type", ""),
                        emotional_impact=sp_data.get("emotional_impact", "")
                    ))

                # è§’è‰²
                for char_data in analysis.get("characters", []):
                    result.characters.append(CharacterAnalysis(
                        name=char_data.get("name", ""),
                        first_appearance=char_data.get("first_appearance", 0),
                        role_type=char_data.get("role_type", ""),
                        appearance_description=char_data.get("appearance_description", ""),
                        personality_traits=char_data.get("personality_traits", [])
                    ))

                # åœºæ™¯
                for scene_data in analysis.get("scenes", []):
                    result.scenes.append(SceneAnalysis(
                        start_time=scene_data.get("start_time", 0),
                        end_time=scene_data.get("end_time", 0),
                        scene_name=scene_data.get("scene_name", ""),
                        location_type=scene_data.get("location_type", ""),
                        atmosphere=scene_data.get("atmosphere", ""),
                        lighting=scene_data.get("lighting", ""),
                        key_elements=scene_data.get("key_elements", [])
                    ))

                # åˆ†é•œ
                for shot_data in analysis.get("shots", []):
                    result.shots.append(ShotAnalysis(
                        timestamp=shot_data.get("timestamp", 0),
                        shot_type=shot_data.get("shot_type", ""),
                        camera_angle=shot_data.get("camera_angle", ""),
                        camera_movement=shot_data.get("camera_movement", ""),
                        composition=shot_data.get("composition", ""),
                        purpose=shot_data.get("purpose", "")
                    ))

            # Step 5: ç”Ÿæˆä¸“ä¸šåˆ†é•œè„šæœ¬ (ä¸­æ–‡)
            if progress_callback:
                progress_callback(5, total_steps, "ç”Ÿæˆåˆ†é•œè„šæœ¬...")

            storyboard = self.claude_analyzer.generate_storyboard(frames_data, video_info)
            result.storyboard = storyboard

            # Step 6: ç”Ÿæˆå¸§æ ‡ç­¾
            if progress_callback:
                progress_callback(6, total_steps, "ç”Ÿæˆæ ‡ç­¾...")

            for frame in result.frames[:20]:  # åªä¸ºå‰20å¸§ç”Ÿæˆæ ‡ç­¾
                tags = self.claude_analyzer.generate_frame_tags(frame.to_dict())
                frame.tags = tags

            # å…³è”å¸§ä¸åˆ†æé¡¹
            self._link_frames_to_analysis(result)

            result.status = AnalysisStatus.COMPLETED
            result.completed_at = datetime.now().isoformat()

            # ä¿å­˜ç»“æœ
            self.save_result(result)

        except Exception as e:
            result.status = AnalysisStatus.FAILED
            result.error_message = str(e)
            import traceback
            traceback.print_exc()

        return result

    def _link_frames_to_analysis(self, result: VideoAnalysisResult):
        """å°†å¸§å…³è”åˆ°åˆ†æé¡¹ç›®"""
        for story_point in result.story_points:
            # æ‰¾åˆ°æœ€è¿‘çš„å¸§
            closest_frame = min(
                result.frames,
                key=lambda f: abs(f.timestamp - story_point.timestamp),
                default=None
            )
            if closest_frame:
                story_point.related_frames.append(closest_frame.id)

        for character in result.characters:
            # æ‰¾åˆ°è§’è‰²é¦–æ¬¡å‡ºç°é™„è¿‘çš„å¸§
            closest_frame = min(
                result.frames,
                key=lambda f: abs(f.timestamp - character.first_appearance),
                default=None
            )
            if closest_frame:
                character.related_frames.append(closest_frame.id)

        for scene in result.scenes:
            # æ‰¾åˆ°åœºæ™¯æ—¶é—´èŒƒå›´å†…çš„å¸§
            for frame in result.frames:
                if scene.start_time <= frame.timestamp <= scene.end_time:
                    scene.related_frames.append(frame.id)

        for shot in result.shots:
            # æ‰¾åˆ°æœ€è¿‘çš„å¸§
            closest_frame = min(
                result.frames,
                key=lambda f: abs(f.timestamp - shot.timestamp),
                default=None
            )
            if closest_frame:
                shot.related_frame = closest_frame.id

    def save_result(self, result: VideoAnalysisResult, filename: str = None) -> str:
        """ä¿å­˜åˆ†æç»“æœä¸ºJSON"""
        if filename is None:
            filename = f"analysis_{result.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        filepath = os.path.join(self.output_dir, filename)

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)

        return filepath

    def load_result(self, filepath: str) -> VideoAnalysisResult:
        """åŠ è½½åˆ†æç»“æœ"""
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)

        result = VideoAnalysisResult(
            id=data.get("id", ""),
            video_path=data.get("video_path", ""),
            video_name=data.get("video_name", ""),
            duration=data.get("duration", 0),
            fps=data.get("fps", 0),
            resolution=tuple(data.get("resolution", [0, 0])),
            story_summary=data.get("story_summary", ""),
            story_structure=data.get("story_structure", ""),
            status=AnalysisStatus(data.get("status", "pending")),
            created_at=data.get("created_at", ""),
            completed_at=data.get("completed_at", ""),
            error_message=data.get("error_message", "")
        )

        # åŠ è½½å¸§
        for frame_data in data.get("frames", []):
            result.frames.append(ExtractedFrame(
                id=frame_data.get("id", ""),
                timestamp=frame_data.get("timestamp", 0),
                frame_number=frame_data.get("frame_number", 0),
                frame_type=FrameType(frame_data.get("frame_type", "interval")),
                image_path=frame_data.get("image_path", ""),
                ocr_text=frame_data.get("ocr_text", ""),
                ocr_confidence=frame_data.get("ocr_confidence", 0),
                tags=frame_data.get("tags", []),
                scene_description=frame_data.get("scene_description", "")
            ))

        # åŠ è½½å…¶ä»–åˆ†æé¡¹...
        for sp_data in data.get("story_points", []):
            result.story_points.append(StoryPoint(**sp_data))

        for char_data in data.get("characters", []):
            result.characters.append(CharacterAnalysis(**char_data))

        for scene_data in data.get("scenes", []):
            result.scenes.append(SceneAnalysis(**scene_data))

        for shot_data in data.get("shots", []):
            result.shots.append(ShotAnalysis(**shot_data))

        return result

    def update_item(self, result_id: str, item_type: str, item_id: str, updates: Dict) -> bool:
        """
        æ›´æ–°åˆ†æç»“æœä¸­çš„æŸä¸€é¡¹

        Args:
            result_id: åˆ†æç»“æœID
            item_type: é¡¹ç›®ç±»å‹ (story_point, character, scene, shot, frame)
            item_id: é¡¹ç›®ID
            updates: æ›´æ–°å†…å®¹

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if self._current_result is None or self._current_result.id != result_id:
            return False

        item_list = None
        if item_type == "story_point":
            item_list = self._current_result.story_points
        elif item_type == "character":
            item_list = self._current_result.characters
        elif item_type == "scene":
            item_list = self._current_result.scenes
        elif item_type == "shot":
            item_list = self._current_result.shots
        elif item_type == "frame":
            item_list = self._current_result.frames
        else:
            return False

        for item in item_list:
            if item.id == item_id:
                for key, value in updates.items():
                    if hasattr(item, key):
                        setattr(item, key, value)
                return True

        return False

    def get_current_result(self) -> Optional[VideoAnalysisResult]:
        """è·å–å½“å‰åˆ†æç»“æœ"""
        return self._current_result


class PDFReportGenerator:
    """PDF æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        pass

    def generate_report(self, result: VideoAnalysisResult, output_path: str) -> str:
        """
        ç”Ÿæˆ PDF æŠ¥å‘Š

        ä½¿ç”¨ reportlab ç”Ÿæˆç²¾ç¾çš„PDFæŠ¥å‘Š
        """
        try:
            from reportlab.lib import colors
            from reportlab.lib.pagesizes import A4
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import cm
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, PageBreak
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
        except ImportError:
            return self._generate_simple_html_report(result, output_path)

        # æ³¨å†Œä¸­æ–‡å­—ä½“
        try:
            pdfmetrics.registerFont(TTFont('SimHei', 'simhei.ttf'))
            font_name = 'SimHei'
        except:
            font_name = 'Helvetica'

        doc = SimpleDocTemplate(output_path, pagesize=A4)
        styles = getSampleStyleSheet()

        # è‡ªå®šä¹‰æ ·å¼
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=24,
            spaceAfter=30
        )

        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=16,
            spaceAfter=12
        )

        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            spaceAfter=8
        )

        elements = []

        # å°é¢
        elements.append(Paragraph(f"è§†é¢‘åˆ†ææŠ¥å‘Š", title_style))
        elements.append(Spacer(1, 20))
        elements.append(Paragraph(f"è§†é¢‘: {result.video_name}", body_style))
        elements.append(Paragraph(f"æ—¶é•¿: {result._format_duration()}", body_style))
        elements.append(Paragraph(f"åˆ†è¾¨ç‡: {result.resolution[0]}x{result.resolution[1]}", body_style))
        elements.append(Paragraph(f"ç”Ÿæˆæ—¶é—´: {result.completed_at}", body_style))
        elements.append(PageBreak())

        # æ•…äº‹æ¦‚è¦
        elements.append(Paragraph("ä¸€ã€æ•…äº‹æ¦‚è¦", heading_style))
        elements.append(Paragraph(result.story_summary or "æš‚æ— ", body_style))
        elements.append(Spacer(1, 20))

        # æ•…äº‹ç»“æ„
        elements.append(Paragraph("äºŒã€æ•…äº‹ç»“æ„", heading_style))
        elements.append(Paragraph(result.story_structure or "æš‚æ— ", body_style))
        elements.append(Spacer(1, 20))

        # è§’è‰²åˆ†æ
        elements.append(Paragraph("ä¸‰ã€è§’è‰²åˆ†æ", heading_style))
        for char in result.characters:
            elements.append(Paragraph(f"<b>{char.name}</b> ({char.role_type})", body_style))
            elements.append(Paragraph(f"å¤–è²Œ: {char.appearance_description}", body_style))
            if char.personality_traits:
                elements.append(Paragraph(f"æ€§æ ¼: {', '.join(char.personality_traits)}", body_style))
            elements.append(Spacer(1, 10))
        elements.append(PageBreak())

        # åœºæ™¯åˆ†æ
        elements.append(Paragraph("å››ã€åœºæ™¯åˆ†æ", heading_style))
        for scene in result.scenes:
            time_range = f"{self._format_time(scene.start_time)} - {self._format_time(scene.end_time)}"
            elements.append(Paragraph(f"<b>{scene.scene_name}</b> [{time_range}]", body_style))
            elements.append(Paragraph(f"ç±»å‹: {scene.location_type} | æ°›å›´: {scene.atmosphere}", body_style))
            elements.append(Spacer(1, 10))
        elements.append(PageBreak())

        # åˆ†é•œåˆ†æ
        elements.append(Paragraph("äº”ã€åˆ†é•œåˆ†æ", heading_style))
        for shot in result.shots:
            elements.append(Paragraph(
                f"[{self._format_time(shot.timestamp)}] {shot.shot_type} | {shot.camera_angle} | {shot.purpose}",
                body_style
            ))
        elements.append(PageBreak())

        # å…³é”®å¸§æ—¶é—´è½´
        elements.append(Paragraph("å…­ã€å…³é”®å¸§æ—¶é—´è½´", heading_style))
        for frame in result.frames[:30]:  # åªæ˜¾ç¤ºå‰30å¸§
            tags_str = ", ".join(frame.tags) if frame.tags else ""
            elements.append(Paragraph(
                f"[{frame.format_timestamp()}] {tags_str}",
                body_style
            ))
            if frame.ocr_text:
                elements.append(Paragraph(f"æ–‡å­—: {frame.ocr_text[:100]}...", body_style))
            elements.append(Spacer(1, 5))

        # ç”Ÿæˆ PDF
        doc.build(elements)
        return output_path

    def _format_time(self, seconds: float) -> str:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"

    def _generate_simple_html_report(self, result: VideoAnalysisResult, output_path: str) -> str:
        """ç”Ÿæˆç®€å•çš„ HTML æŠ¥å‘Šï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        html_path = output_path.replace(".pdf", ".html")

        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>è§†é¢‘åˆ†ææŠ¥å‘Š - {result.video_name}</title>
    <style>
        body {{ font-family: "Microsoft YaHei", sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #333; border-bottom: 2px solid #333; padding-bottom: 10px; }}
        h2 {{ color: #666; margin-top: 30px; }}
        .meta {{ color: #888; margin-bottom: 20px; }}
        .section {{ margin-bottom: 30px; }}
        .item {{ background: #f5f5f5; padding: 10px; margin: 10px 0; border-radius: 5px; }}
        .timestamp {{ color: #007bff; font-weight: bold; }}
        .tag {{ display: inline-block; background: #e0e0e0; padding: 2px 8px; margin: 2px; border-radius: 10px; font-size: 12px; }}
    </style>
</head>
<body>
    <h1>è§†é¢‘åˆ†ææŠ¥å‘Š</h1>
    <div class="meta">
        <p><strong>è§†é¢‘:</strong> {result.video_name}</p>
        <p><strong>æ—¶é•¿:</strong> {result._format_duration()}</p>
        <p><strong>åˆ†è¾¨ç‡:</strong> {result.resolution[0]}x{result.resolution[1]}</p>
    </div>

    <div class="section">
        <h2>æ•…äº‹æ¦‚è¦</h2>
        <p>{result.story_summary or 'æš‚æ— '}</p>
    </div>

    <div class="section">
        <h2>æ•…äº‹ç»“æ„</h2>
        <p>{result.story_structure or 'æš‚æ— '}</p>
    </div>

    <div class="section">
        <h2>è§’è‰²åˆ†æ</h2>
        {"".join([f'<div class="item"><strong>{c.name}</strong> ({c.role_type})<br/>{c.appearance_description}</div>' for c in result.characters])}
    </div>

    <div class="section">
        <h2>åœºæ™¯åˆ†æ</h2>
        {"".join([f'<div class="item"><strong>{s.scene_name}</strong> [{self._format_time(s.start_time)}-{self._format_time(s.end_time)}]<br/>æ°›å›´: {s.atmosphere}</div>' for s in result.scenes])}
    </div>

    <div class="section">
        <h2>åˆ†é•œåˆ†æ</h2>
        {"".join([f'<div class="item"><span class="timestamp">[{self._format_time(sh.timestamp)}]</span> {sh.shot_type} | {sh.camera_angle} | {sh.purpose}</div>' for sh in result.shots])}
    </div>

    <div class="section">
        <h2>å…³é”®å¸§æ—¶é—´è½´</h2>
        {"".join([f'<div class="item"><span class="timestamp">[{f.format_timestamp()}]</span> {"".join([f"<span class=tag>{t}</span>" for t in f.tags])}<br/>{f.ocr_text[:100] if f.ocr_text else ""}</div>' for f in result.frames[:30]])}
    </div>
</body>
</html>"""

        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        return html_path


# ä¾¿æ·å‡½æ•°
def analyze_video(
    video_path: str,
    output_dir: str = None,
    extraction_mode: str = "interval",
    interval_seconds: float = 5.0,
    max_frames: int = 50,
    generate_pdf: bool = True
) -> Tuple[VideoAnalysisResult, str]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æè§†é¢‘å¹¶ç”ŸæˆæŠ¥å‘Š

    Args:
        video_path: è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        extraction_mode: æŠ½å¸§æ¨¡å¼
        interval_seconds: é—´éš”ç§’æ•°
        max_frames: æœ€å¤§å¸§æ•°
        generate_pdf: æ˜¯å¦ç”ŸæˆPDF

    Returns:
        (åˆ†æç»“æœ, æŠ¥å‘Šè·¯å¾„)
    """
    analyzer = VideoAnalyzer(output_dir=output_dir)
    result = analyzer.analyze_video(
        video_path,
        extraction_mode=extraction_mode,
        interval_seconds=interval_seconds,
        max_frames=max_frames
    )

    report_path = ""
    if generate_pdf and result.status == AnalysisStatus.COMPLETED:
        pdf_generator = PDFReportGenerator()
        report_path = os.path.join(
            analyzer.output_dir,
            f"report_{result.id}.pdf"
        )
        report_path = pdf_generator.generate_report(result, report_path)

    return result, report_path


def run_self_tests() -> bool:
    """
    æ³¢æ™®å°”çš„è¯ä¼ªä¸»ä¹‰: å¥½çš„ä»£ç åº”è¯¥æ˜¯å¯æµ‹è¯•çš„

    è¿è¡Œè‡ªæ£€æµ‹è¯•ï¼Œè¿”å›æ˜¯å¦å…¨éƒ¨é€šè¿‡ã€‚
    """
    print("=" * 50)
    print("Popper Falsifiability Tests")
    print("=" * 50)

    tests_passed = 0
    tests_failed = 0

    # Test 1: æ ¼å¼åŒ–å‡½æ•°æµ‹è¯•
    try:
        assert format_timestamp(3661.5) == "01:01:01.500", "Timestamp format error"
        assert format_timestamp(0) == "00:00:00.000", "Zero value format error"
        print("[PASS] Format function test")
        tests_passed += 1
    except AssertionError as e:
        print(f"[FAIL] Format function test: {e}")
        tests_failed += 1

    # Test 2: é…ç½®ç±»æµ‹è¯•
    try:
        config = AnalyzerConfig()
        assert config.ollama_port == 11434, "Default port error"
        assert config.default_max_frames == 50, "Default frames error"
        print("[PASS] Config class test")
        tests_passed += 1
    except AssertionError as e:
        print(f"[FAIL] Config class test: {e}")
        tests_failed += 1

    # Test 3: æšä¸¾å®Œæ•´æ€§æµ‹è¯• (äºšé‡Œå£«å¤šå¾·)
    try:
        assert len(AnalysisStatus) >= 6, "AnalysisStatus enum incomplete"
        assert len(FrameType) >= 4, "FrameType enum incomplete"
        assert len(ShotType) >= 5, "ShotType enum incomplete"
        print("[PASS] Enum completeness test (Aristotle)")
        tests_passed += 1
    except AssertionError as e:
        print(f"[FAIL] Enum completeness test: {e}")
        tests_failed += 1

    # Test 4: æ•°æ®ç±»åºåˆ—åŒ–æµ‹è¯•
    try:
        frame = ExtractedFrame(timestamp=10.5, frame_number=100)
        frame_dict = frame.to_dict()
        assert "timestamp" in frame_dict, "Serialization missing timestamp"
        assert "id" in frame_dict, "Serialization missing id"
        print("[PASS] Dataclass serialization test")
        tests_passed += 1
    except AssertionError as e:
        print(f"[FAIL] Dataclass serialization test: {e}")
        tests_failed += 1

    print("-" * 50)
    print(f"Results: {tests_passed} passed, {tests_failed} failed")
    print("=" * 50)

    return tests_failed == 0


if __name__ == "__main__":
    """
    ç¦…å®—çš„ç®€æ´ä¹‹é“: å°‘å³æ˜¯å¤š

    é¦™å†œçš„ä¿¡æ¯è®º: æœ€å¤§åŒ–ä¿¡å·ï¼Œæœ€å°åŒ–å™ªéŸ³
    """
    import sys

    print("è§†é¢‘åˆ†ææ¨¡å— v2.0.0")
    print("-" * 30)

    # è¿è¡Œè‡ªæ£€æµ‹è¯•
    if "--test" in sys.argv:
        success = run_self_tests()
        sys.exit(0 if success else 1)

    # æµ‹è¯•è¿æ¥
    print("\nè¿æ¥çŠ¶æ€æ£€æŸ¥:")
    analyzer = VideoAnalyzer()
    connections = analyzer.test_connections()
    for name, (ok, msg) in connections.items():
        status = "âœ“" if ok else "âœ—"
        print(f"  {status} {name}: {msg}")
